#!/usr/bin/env python3
# -*- coding: utf-8 -*-

# å¯¼å…¥HTTPè¯·æ±‚åº“
import requests
# å¯¼å…¥æ­£åˆ™è¡¨è¾¾å¼åº“
import re
# å¯¼å…¥æ—¶é—´å¤„ç†æ¨¡å—
from datetime import datetime, timedelta

# ä¸Šæ¸¸è§„åˆ™æºé…ç½®åˆ—è¡¨
RULE_SOURCES = [
    {"name": "AdRules", "url": "https://raw.githubusercontent.com/Cats-Team/AdRules/main/adrules.list"},
    {"name": "anti-ad", "url": "https://anti-ad.net/surge2.txt"},
    {"name": "blackmatrix7-Domain", "url": "https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/master/rule/Loon/Advertising/Advertising_Domain.list"},
    {"name": "blackmatrix7-Advertising", "url": "https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/master/rule/Loon/Advertising/Advertising.list"},
]

# è¾“å‡ºæ–‡ä»¶å
OUTPUT_FILE = "Loon_rules.txt"
# è®¢é˜…åœ°å€ç”¨äºæ–‡ä»¶å¤´
SUBSCRIBE_URL = "https://ddcm1349.github.io/Loon/Loon_rules.txt"


def get_beijing_time():
    # è·å–UTCæ—¶é—´
    utc_now = datetime.utcnow()
    # åŠ 8å°æ—¶è½¬ä¸ºåŒ—äº¬æ—¶é—´
    beijing_time = utc_now + timedelta(hours=8)
    # æ ¼å¼åŒ–æ—¶é—´å­—ç¬¦ä¸²
    return beijing_time.strftime('%Y-%m-%d %H:%M:%S')


def is_valid_domain(domain):
    # æ£€æŸ¥ç©ºå€¼æˆ–è¶…é•¿
    if not domain or len(domain) > 253:
        return False
    # æ£€æŸ¥åˆæ³•å­—ç¬¦
    if not re.match(r'^[a-z0-9\-\.]+$', domain):
        return False
    # æ£€æŸ¥è¿ç»­ç‚¹æˆ–é¦–å°¾ç‚¹
    if '..' in domain or domain.startswith('.') or domain.endswith('.'):
        return False
    # åˆ†å‰²å„çº§æ ‡ç­¾
    labels = domain.split('.')
    # è‡³å°‘ä¸¤çº§
    if len(labels) < 2:
        return False
    # æ£€æŸ¥æ¯çº§æ ‡ç­¾
    for label in labels:
        # é•¿åº¦æ£€æŸ¥
        if not 1 <= len(label) <= 63:
            return False
        # æ¨ªæ ä½ç½®æ£€æŸ¥
        if label.startswith('-') or label.endswith('-'):
            return False
    # é¡¶çº§åŸŸåä¸èƒ½çº¯æ•°å­—
    if labels[-1].isdigit():
        return False
    return True


def is_valid_ip_cidr(ip_str):
    # IPv4 CIDRæ­£åˆ™
    pattern = r'^(\d{1,3}\.){3}\d{1,3}/\d{1,2}$'
    # æ­£åˆ™åŒ¹é…æ£€æŸ¥
    if not re.match(pattern, ip_str):
        return False
    try:
        # åˆ†å‰²IPå’Œæ©ç 
        ip_part, mask_part = ip_str.split('/')
        # æ©ç è½¬æ•´æ•°
        mask = int(mask_part)
        # æ©ç èŒƒå›´æ£€æŸ¥
        if not (0 <= mask <= 32):
            return False
        # åˆ†å‰²IPå››æ®µ
        parts = ip_part.split('.')
        # æ¯æ®µèŒƒå›´æ£€æŸ¥
        for part in parts:
            num = int(part)
            if not 0 <= num <= 255:
                return False
        return True
    except:
        return False


def is_valid_ip_cidr6(ip_str):
    # å¿…é¡»å«æ–œæ 
    if '/' not in ip_str:
        return False
    try:
        # ä»å³åˆ†å‰²é¿å…å†’å·å¹²æ‰°
        ip_part, mask_part = ip_str.rsplit('/', 1)
        # æ©ç è½¬æ•´æ•°
        mask = int(mask_part)
        # IPv6æ©ç èŒƒå›´
        if not (0 <= mask <= 128):
            return False
        # å¿…é¡»å«å†’å·
        if ':' not in ip_part:
            return False
        return True
    except:
        return False


def is_valid_pure_ip(ip_str):
    # ä¸èƒ½æœ‰æ–œæ 
    if '/' in ip_str:
        return False
    # åªå…è®¸æ•°å­—å’Œç‚¹
    if not re.match(r'^[\d\.]+$', ip_str):
        return False
    # åˆ†å‰²å››æ®µ
    parts = ip_str.split('.')
    # å¿…é¡»å››æ®µ
    if len(parts) != 4:
        return False
    try:
        # æ£€æŸ¥æ¯æ®µ
        for part in parts:
            # ä¸èƒ½ä¸ºç©º
            if not part:
                return False
            # è½¬æ•´æ•°
            num = int(part)
            # èŒƒå›´0-255
            if not 0 <= num <= 255:
                return False
            # ç¦æ­¢å‰å¯¼é›¶
            if len(part) > 1 and part[0] == '0':
                return False
        return True
    except ValueError:
        return False


def is_loon_format(line):
    # è½¬å¤§å†™æ¯”è¾ƒ
    upper_line = line.upper()
    # å®šä¹‰æ‰€æœ‰å‰ç¼€
    prefixes = ('DOMAIN,', 'DOMAIN-SUFFIX,', 'DOMAIN-KEYWORD,', 'IP-CIDR,', 'IP-CIDR6,')
    # æ£€æŸ¥æ˜¯å¦åŒ¹é…ä»»ä¸€å‰ç¼€
    for prefix in prefixes:
        if upper_line.startswith(prefix):
            return True
    return False


def parse_loon_rule(line):
    # é€—å·åˆ†å‰²
    parts = line.split(',')
    # è‡³å°‘ä¸¤éƒ¨åˆ†
    if len(parts) < 2:
        return None
    # æå–ç±»å‹
    rule_type = parts[0].strip().upper()
    # æå–å€¼
    value = parts[1].strip()
    # æå–å‚æ•°
    params = [p.strip() for p in parts[2:]] if len(parts) > 2 else []
    return (rule_type, value, params)


def normalize_rule(rule_type, value, params):
    # åˆ†ç¦»no-resolve
    other_params = [p for p in params if p.lower() != 'no-resolve']
    # æ£€æŸ¥æ˜¯å¦æœ‰no-resolve
    has_no_resolve = any(p.lower() == 'no-resolve' for p in params)
    # é‡ç»„å‚æ•°
    final_params = other_params.copy()
    if has_no_resolve:
        final_params.append('no-resolve')
    # æœ‰å‚æ•°åˆ™æ‹¼æ¥
    if final_params:
        return f"{rule_type},{value},{','.join(final_params)}"
    return f"{rule_type},{value}"


def process_loon_line(line):
    # è§£æè§„åˆ™
    parsed = parse_loon_rule(line)
    if parsed is None:
        return None
    # è§£åŒ…
    rule_type, value, params = parsed
    # æ”¯æŒç±»å‹é›†åˆ
    valid_types = {'DOMAIN', 'DOMAIN-SUFFIX', 'DOMAIN-KEYWORD', 'IP-CIDR', 'IP-CIDR6'}
    # ç±»å‹æ£€æŸ¥
    if rule_type not in valid_types:
        return None
    # åŸŸåç±»å‹æ¸…æ´—no-resolve
    domain_types = {'DOMAIN', 'DOMAIN-SUFFIX', 'DOMAIN-KEYWORD'}
    if rule_type in domain_types:
        params = [p for p in params if p.lower() != 'no-resolve']
    # æ ¹æ®ç±»å‹éªŒè¯å€¼
    if rule_type in ('DOMAIN', 'DOMAIN-SUFFIX', 'DOMAIN-KEYWORD'):
        value_lower = value.lower()
        is_ip = is_valid_pure_ip(value_lower)
        is_domain = is_valid_domain(value_lower)
        if not is_ip and not is_domain:
            return None
    elif rule_type == 'IP-CIDR':
        if not is_valid_ip_cidr(value):
            return None
    elif rule_type == 'IP-CIDR6':
        if not is_valid_ip_cidr6(value):
            return None
    # æ ‡å‡†åŒ–è¾“å‡º
    return normalize_rule(rule_type, value, params)


def process_line_smart(line):
    # å»ç©ºç™½
    line = line.strip()
    # è·³è¿‡ç©ºè¡Œ
    if not line:
        return None
    # è·³è¿‡æ³¨é‡Š
    if line.startswith('#') or line.startswith('!') or line.startswith('['):
        return None
    # Loonæ ¼å¼å¤„ç†
    if is_loon_format(line):
        return process_loon_line(line)
    # IPv4 CIDRå¤„ç†
    if is_valid_ip_cidr(line):
        return f"IP-CIDR,{line}"
    # IPv6 CIDRå¤„ç†
    if is_valid_ip_cidr6(line):
        return f"IP-CIDR6,{line}"
    # çº¯IPv4å¤„ç†
    if is_valid_pure_ip(line):
        return f"DOMAIN,{line}"
    # å¸¦ç‚¹åŸŸåå¤„ç†
    if line.startswith('.'):
        domain = line[1:].lower()
        if is_valid_domain(domain):
            return f"DOMAIN-SUFFIX,{domain}"
        return None
    # æ™®é€šåŸŸåå¤„ç†
    domain = line.lower()
    if is_valid_domain(domain):
        return f"DOMAIN,{domain}"
    return None


def get_rule_key(rule):
    # è§£æè§„åˆ™
    parsed = parse_loon_rule(rule)
    if parsed is None:
        return rule
    # è§£åŒ…
    rule_type, value, params = parsed
    # å€¼è½¬å°å†™
    value_lower = value.lower()
    # æ£€æŸ¥no-resolve
    has_no_resolve = any(p.lower() == 'no-resolve' for p in params)
    # å…¶ä»–å‚æ•°æ’åº
    other_params = sorted([p.lower() for p in params if p.lower() != 'no-resolve'])
    # è¿”å›å››å…ƒç»„é”®
    return (rule_type.upper(), value_lower, tuple(other_params), has_no_resolve)


def get_rule_priority(rule):
    # è§£æè§„åˆ™
    parsed = parse_loon_rule(rule)
    if parsed is None:
        return 99
    # æå–ç±»å‹
    rule_type = parsed[0]
    # ä¼˜å…ˆçº§æ˜ å°„
    priority_map = {
        'DOMAIN-KEYWORD': 1,
        'DOMAIN': 2,
        'DOMAIN-SUFFIX': 3,
        'IP-CIDR': 4,
        'IP-CIDR6': 5,
    }
    return priority_map.get(rule_type, 99)


def ip_to_int(ip_str):
    # å°è¯•è½¬æ¢
    try:
        parts = ip_str.split('.')
        return (int(parts[0]) << 24) + (int(parts[1]) << 16) + (int(parts[2]) << 8) + int(parts[3])
    except:
        return None


def remove_ip_domain_redundant(domain_rules_with_value, ip_cidr_list):
    # ç©ºæ£€æŸ¥
    if not domain_rules_with_value or not ip_cidr_list:
        return [r for _, r in domain_rules_with_value], 0
    # åˆå§‹åŒ–
    removed = 0
    kept_rules = []
    # éå†åŸŸåè§„åˆ™
    for domain, rule in domain_rules_with_value:
        # è½¬IPæ•´æ•°
        ip_int = ip_to_int(domain)
        # ä¸æ˜¯IPåˆ™ä¿ç•™
        if ip_int is None:
            kept_rules.append(rule)
            continue
        # æ£€æŸ¥æ˜¯å¦è¢«IPæ®µåŒ…å«
        is_covered = False
        for kept_ip, kept_mask, _ in ip_cidr_list:
            shift = 32 - kept_mask
            if shift < 0:
                continue
            if (ip_int >> shift) == (kept_ip >> shift):
                is_covered = True
                break
        # å†³å®šä¿ç•™æˆ–ç§»é™¤
        if is_covered:
            removed += 1
        else:
            kept_rules.append(rule)
    return kept_rules, removed


def dedup_rules(rules):
    # ç¬¬ä¸€å±‚ï¼šå®Œå…¨ç›¸åŒå»é‡
    seen_keys = {}
    unique_rules = []
    dup_removed = 0
    for rule in rules:
        key = get_rule_key(rule)
        if key not in seen_keys:
            seen_keys[key] = rule
            unique_rules.append(rule)
        else:
            dup_removed += 1
    rules = unique_rules
    
    # åˆ†ç±»æ”¶é›†
    ip_cidr_rules = []
    ip_cidr6_rules = []
    domain_rules = []
    suffix_rules = []
    keyword_rules = []
    for rule in rules:
        parsed = parse_loon_rule(rule)
        if parsed is None:
            continue
        rule_type, value, params = parsed
        if rule_type == 'IP-CIDR':
            try:
                ip_str, mask_str = value.split('/')
                mask = int(mask_str)
                ip_parts = ip_str.split('.')
                ip_int = (int(ip_parts[0]) << 24) + (int(ip_parts[1]) << 16) + (int(ip_parts[2]) << 8) + int(ip_parts[3])
                ip_cidr_rules.append((ip_int, mask, rule))
            except:
                pass
        elif rule_type == 'IP-CIDR6':
            ip_cidr6_rules.append((value.lower(), rule))
        elif rule_type == 'DOMAIN':
            domain_rules.append((value.lower(), rule))
        elif rule_type == 'DOMAIN-SUFFIX':
            suffix_rules.append((value.lower(), rule))
        elif rule_type == 'DOMAIN-KEYWORD':
            keyword_rules.append((value.lower(), rule))
    
    # ç¬¬äºŒå±‚ï¼šIP-CIDRåŒ…å«å»é‡
    ip_cidr_rules.sort(key=lambda x: -x[1])
    kept_ip_cidr = []
    removed_ip_count = 0
    for ip_int, mask, rule in ip_cidr_rules:
        is_covered = False
        for kept_ip, kept_mask, _ in kept_ip_cidr:
            if kept_mask <= mask:
                continue
            shift = 32 - kept_mask
            if shift < 0:
                continue
            if (ip_int >> shift) == (kept_ip >> shift):
                is_covered = True
                break
        if is_covered:
            removed_ip_count += 1
        else:
            kept_ip_cidr.append((ip_int, mask, rule))
    
    # ç¬¬ä¸‰å±‚.1ï¼šDOMAINè¢«SUFFIXåŒ…å«
    suffix_domains = set(d for d, _ in suffix_rules)
    final_domain_rules = []
    removed_domain_count = 0
    for domain, rule in domain_rules:
        parts = domain.split('.')
        is_covered = False
        for i in range(len(parts)):
            suffix = '.'.join(parts[i:])
            if suffix in suffix_domains:
                is_covered = True
                break
        if is_covered:
            removed_domain_count += 1
        else:
            final_domain_rules.append(rule)
    
    # ç¬¬ä¸‰å±‚.2ï¼šSUFFIXå†…éƒ¨åŒ…å«
    suffix_rules.sort(key=lambda x: len(x[0].split('.')))
    kept_suffix_domains = set()
    final_suffix_rules = []
    redundant_suffix_count = 0
    for domain, rule in suffix_rules:
        parts = domain.split('.')
        is_redundant = False
        for i in range(1, len(parts)):
            parent_suffix = '.'.join(parts[i:])
            if parent_suffix in kept_suffix_domains:
                is_redundant = True
                break
        if is_redundant:
            redundant_suffix_count += 1
        else:
            kept_suffix_domains.add(domain)
            final_suffix_rules.append(rule)
    
    # è·¨ç±»å‹å»é‡
    final_domain_rules_with_value = [(d, r) for d, r in domain_rules if r in final_domain_rules]
    final_domain_rules, cross_removed = remove_ip_domain_redundant(final_domain_rules_with_value, kept_ip_cidr)
    
    # åˆå¹¶ç»“æœ
    final_rules = []
    final_rules.extend(keyword_rules)
    final_rules.extend(final_domain_rules)
    final_rules.extend(final_suffix_rules)
    final_rules.extend([r for _, _, r in kept_ip_cidr])
    final_rules.extend([r for _, r in ip_cidr6_rules])
    
    total_removed = dup_removed + removed_ip_count + removed_domain_count + redundant_suffix_count + cross_removed
    return final_rules, total_removed


def main():
    # æ‰“å°å¯åŠ¨ä¿¡æ¯
    print(f"[{get_beijing_time()}] ğŸš€ å¯åŠ¨è§„åˆ™æŠ“å–...")
    print("=" * 60, flush=True)
    
    # åˆå§‹åŒ–
    all_rules = []
    source_stats = []
    headers = {'User-Agent': 'Mozilla/5.0 (compatible; RuleFetcher/1.0)'}
    
    # éå†å„æº
    for src in RULE_SOURCES:
        try:
            print(f"ğŸ“¥ æ‹‰å–: {src['name']}...", flush=True)
            resp = requests.get(src['url'], timeout=30, headers=headers)
            resp.raise_for_status()
            lines = resp.text.splitlines()
            processed = [r for r in (process_line_smart(l) for l in lines) if r is not None]
            
            # å•æºå»é‡
            seen = set()
            unique_processed = []
            for r in processed:
                key = get_rule_key(r)
                if key not in seen:
                    seen.add(key)
                    unique_processed.append(r)
            
            print(f"   åŸå§‹: {len(lines)} | æå–: {len(unique_processed)}", flush=True)
            source_stats.append({"name": src['name'], "raw": len(lines), "valid": len(unique_processed)})
            all_rules.extend(unique_processed)
            print(f"âœ… å®Œæˆ", flush=True)
        except Exception as e:
            print(f"âŒ å¤±è´¥: {e}", flush=True)
            import traceback
            traceback.print_exc()
    
    # å…¨å±€å»é‡
    print("=" * 60, flush=True)
    print(f"ğŸ”„ å…¨å±€å»é‡ä¼˜åŒ–ï¼ˆæ€»è®¡ {len(all_rules)} æ¡ï¼‰...", flush=True)
    final_rules, total_removed = dedup_rules(all_rules)
    final_rules.sort(key=lambda r: (get_rule_priority(r), r.lower()))
    
    # ç»Ÿè®¡
    type_counts = {}
    for r in final_rules:
        parsed = parse_loon_rule(r)
        if parsed:
            t = parsed[0]
            type_counts[t] = type_counts.get(t, 0) + 1
    
    print(f"\nğŸ“Š æœ€ç»ˆç»“æœ: {len(final_rules)} æ¡", flush=True)
    for t, c in sorted(type_counts.items(), key=lambda x: get_rule_priority(f"{x[0]},")):
        print(f"   â€¢ {t}: {c} æ¡", flush=True)
    
    # æ„å»ºæ–‡ä»¶å¤´
    header = [
        f"# Loon_ADåˆºå®¢",
        f"# ç”Ÿæˆæ—¶é—´: {get_beijing_time()}",
        f"# ç»Ÿè®¡: {len(final_rules)} æ¡",
        f"# ä¼˜åŒ–: ç§»é™¤ {total_removed} æ¡å†—ä½™è§„åˆ™",
        f"# è®¢é˜…åœ°å€: {SUBSCRIBE_URL}",
        "# " + "=" * 58
    ]
    for s in source_stats:
        header.append(f"# æº: {s['name']} | åŸå§‹ {s['raw']} | æå– {s['valid']}")
    header.append("# " + "-" * 58)
    for t, c in sorted(type_counts.items(), key=lambda x: get_rule_priority(f"{x[0]},")):
        header.append(f"# {t}: {c}")
    header.append("# " + "=" * 58)
    
    # å†™å…¥æ–‡ä»¶
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        f.write('\n'.join(header) + '\n\n' + '\n'.join(final_rules))
    
    print(f"\nğŸ’¾ å·²ä¿å­˜: {OUTPUT_FILE}", flush=True)
    print(f"[{get_beijing_time()}] ğŸ‰ å®Œæˆ!", flush=True)


if __name__ == "__main__":
    main()
