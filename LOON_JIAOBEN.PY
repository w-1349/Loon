#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import requests
import re
import time
import ipaddress
from datetime import datetime, timedelta
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

# ================= é…ç½®åŒº =================
RULE_SOURCES = [
    {"name": "AdRules", "url": "https://raw.githubusercontent.com/Cats-Team/AdRules/main/adrules.list"},
    {"name": "anti-ad", "url": "https://anti-ad.net/surge2.txt"},
    {"name": "ADG", "url": "https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/master/rule/Loon/Advertising/Advertising.list"},
    {"name": "ADG_Domain", "url": "https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/master/rule/Loon/Advertising/Advertising_Domain.list"},
    {"name": "Privacy", "url": "https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/master/rule/Loon/Privacy/Privacy.list"},
    {"name": "Privacy_Domain", "url": "https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/master/rule/Loon/Privacy/Privacy_Domain.list"},
]

OUTPUT_FILE = "Loon_rules.txt"
REMOVED_LOG_FILE = "loon_removed_details.log"  # è¿‡æ»¤æ˜ç»†æ—¥å¿—
SUBSCRIBE_URL = "https://ddcm1349.github.io/Loon/Loon_rules.txt"

# å±é™©å…³é”®å­—ï¼šé˜²æ­¢è¯¯åˆ åŸºç¡€åŸŸååç¼€æˆ–å…³é”®åŸºç¡€è®¾æ–½
INVALID_KEYWORDS = {
    'com', 'net', 'cn', 'org', 'io', 'co', 'tv', 'cc', 'app', 'dev',
    'com.cn', 'net.cn', 'org.cn', 'gov.cn', 'edu.cn', 'com.hk',
    'ads', 'api', 'cdn', 'static', 'www', 'download', 'upload'
}
# ==========================================

def get_beijing_time():
    """è·å–å½“å‰çš„åŒ—äº¬æ—¶é—´"""
    return (datetime.utcnow() + timedelta(hours=8)).strftime('%Y-%m-%d %H:%M:%S')

def log(msg, level="INFO"):
    """ç¾åŒ–æ§åˆ¶å°è¾“å‡º"""
    timestamp = get_beijing_time()
    prefix = {"INFO": "â„¹ï¸", "OK": "âœ…", "ERROR": "âŒ", "WARN": "âš ï¸"}.get(level, "â€¢")
    print(f"[{timestamp}] {prefix} {msg}", flush=True)

def create_session():
    """é…ç½®å¸¦é‡è¯•æœºåˆ¶çš„ HTTP è¯·æ±‚ä¼šè¯"""
    session = requests.Session()
    retries = Retry(total=3, backoff_factor=1, status_forcelist=[500, 502, 503, 504])
    session.mount("http://", HTTPAdapter(max_retries=retries))
    session.mount("https://", HTTPAdapter(max_retries=retries))
    session.headers.update({"User-Agent": "Mozilla/5.0 LoonRuleEngine/3.5"})
    return session

def is_valid_domain(domain):
    """éªŒè¯åŸŸåæ˜¯å¦åˆæ³•ï¼ˆæ”¯æŒçº¯ IP è¯†åˆ«ï¼‰"""
    if not domain or len(domain) > 253: return False
    if re.match(r'^(\d{1,3}\.){3}\d{1,3}$', domain): return True
    if not re.match(r'^[a-z0-9\-\.]+$', domain): return False
    labels = domain.split('.')
    return len(labels) >= 2 and not labels[-1].isdigit()

def is_dangerous_keyword(rval):
    """ç²¾ç¡®æ£€æµ‹å±é™©å…³é”®å­—ï¼Œé¿å…è¯¯ä¼¤å­åŸŸåï¼ˆå¦‚ api-ads.com ä¸åº”è¢«æ‹¦æˆªï¼‰"""
    rval = rval.lower()
    for k in INVALID_KEYWORDS:
        if rval == k: return True
        if k in rval:
            idx = rval.find(k)
            before = rval[idx-1] if idx > 0 else ''
            after = rval[idx+len(k)] if idx+len(k) < len(rval) else ''
            if (not before or not before.isalnum()) and (not after or not after.isalnum()):
                return True
    return False

def parse_loon_rule(line):
    """å°† Loon è§„åˆ™è¡Œè§£æä¸º (ç±»å‹, å€¼, å‚æ•°åˆ—è¡¨)"""
    parts = line.split(',')
    if len(parts) < 2: return None
    params = [p.strip().lower() for p in parts[2:] if p.strip()]
    return (parts[0].strip().upper(), parts[1].strip(), params)

def normalize_rule_smart(rtype, rval, rparams):
    """æ ‡å‡†åŒ–è¾“å‡ºï¼šåŸŸåç±»å‰¥ç¦»å†—ä½™å‚æ•°ï¼ŒIPç±»ä¿ç•™ no-resolve"""
    rval = rval.lower()
    if rtype in ("DOMAIN", "DOMAIN-SUFFIX", "DOMAIN-KEYWORD"):
        return f"{rtype},{rval}"
    if rtype in ("IP-CIDR", "IP-CIDR6"):
        return f"{rtype},{rval},no-resolve" if "no-resolve" in rparams else f"{rtype},{rval}"
    return f"{rtype},{rval}"

def is_covered_by_trie(val, trie):
    """
    æ ¸å¿ƒç®—æ³•ï¼šé€šè¿‡åç¼€å­—å…¸æ ‘(Trie)åå‘åŒ¹é…ã€‚
    é€»è¾‘ï¼šå¦‚æœå­—å…¸æ ‘ä¸­å·²å­˜åœ¨ example.comï¼Œåˆ™ sub.example.com ä¼šè¿”å› Trueã€‚
    """
    node = trie
    for part in val.split('.')[::-1]: # ä»é¡¶çº§åŸŸåå¼€å§‹é€çº§å¾€å·¦æŸ¥
        if part not in node: return False
        node = node[part]
        if "#" in node: return True # å‘½ä¸­ç»ˆæ­¢ç¬¦ï¼Œè¯´æ˜å·²è¢«çˆ¶åŸŸæ¶µç›–
    return False

def dedup_engine(rules):
    """æè‡´å»é‡å¼•æ“ï¼šå¤„ç†å®Œå…¨é‡å¤ã€é€»è¾‘åŒ…å«ã€å±é™©æ‹¦æˆª"""
    stats = {'danger': 0, 'logic': 0, 'exact': 0}
    seen = set()
    unique_base = []
    log_logic = [] # è®°å½•æœ‰ä»·å€¼çš„é€»è¾‘è¿‡æ»¤

    # 1. ç¬¬ä¸€é˜¶æ®µï¼šå‰”é™¤å®Œå…¨ç›¸åŒçš„ç‰©ç†è¡Œ
    for r in rules:
        p = parse_loon_rule(r)
        if not p: continue
        norm = normalize_rule_smart(*p)
        if norm not in seen:
            seen.add(norm)
            unique_base.append(p)
        else: 
            stats['exact'] += 1 # å®Œå…¨é‡å¤ä¸è¿›è¯¦ç»†æ—¥å¿—ï¼Œä»…è®¡æ•°

    key_rules, suf_raw, dom_raw, ip_raw, ip6_rules = [], [], [], [], []

    # 2. ç¬¬äºŒé˜¶æ®µï¼šåˆ†ç±»ä¸å±é™©å…³é”®å­—è¿‡æ»¤
    for rtype, rval, rparams in unique_base:
        raw_str = normalize_rule_smart(rtype, rval, rparams)
        if rtype == 'DOMAIN-KEYWORD':
            if is_dangerous_keyword(rval):
                stats['danger'] += 1
                log_logic.append(f"[å±é™©æ‹¦æˆª] {raw_str} (å‘½ä¸­å…³é”®å­—é»‘åå•)")
                continue
            key_rules.append(raw_str)
        elif rtype == 'DOMAIN-SUFFIX':
            if rval in INVALID_KEYWORDS:
                stats['danger'] += 1
                log_logic.append(f"[å±é™©æ‹¦æˆª] {raw_str} (ç¦æ­¢é¡¶çº§åŸŸååç¼€)")
                continue
            suf_raw.append((raw_str, rval))
        elif rtype == 'DOMAIN':
            dom_raw.append((raw_str, rval))
        elif rtype == 'IP-CIDR':
            try:
                net = ipaddress.IPv4Network(rval, strict=False)
                ip_raw.append((raw_str, net))
            except: continue
        elif rtype == 'IP-CIDR6':
            ip6_rules.append(raw_str)

    # 3. ç¬¬ä¸‰é˜¶æ®µï¼šåŸŸååç¼€åŒ…å«å»é‡
    # 
    suf_raw.sort(key=lambda x: len(x[1].split('.'))) # æŒ‰åŸŸåé•¿åº¦æ’åºï¼Œä¼˜å…ˆå¤„ç†çˆ¶åŸŸ
    trie, final_suf = {}, []
    for rule_str, val in suf_raw:
        if not is_covered_by_trie(val, trie):
            final_suf.append(rule_str)
            # å°†æ–°åŸŸååŠ å…¥ Trie æ ‘
            node = trie
            for part in val.split('.')[::-1]: node = node.setdefault(part, {})
            node["#"] = True # è®¾ç½®ç»ˆæ­¢ç¬¦
        else: 
            stats['logic'] += 1
            log_logic.append(f"[é€»è¾‘è¦†ç›–] {rule_str:<40} # å·²è¢«ä¸Šçº§åç¼€è§„åˆ™æ¶µç›–")

    # 4. ç¬¬å››é˜¶æ®µï¼šç²¾ç¡®åŸŸååŒ…å«å»é‡
    final_dom = []
    for r, v in dom_raw:
        if is_covered_by_trie(v, trie): 
            stats['logic'] += 1
            log_logic.append(f"[é€»è¾‘è¦†ç›–] {r:<40} # å·²è¢«åç¼€è§„åˆ™(DOMAIN-SUFFIX)æ¶µç›–")
        else: 
            final_dom.append(r)

    # 5. ç¬¬äº”é˜¶æ®µï¼šIP CIDR æ©ç åŒ…å«å»é‡ (å¤§ç½‘æ®µè¦†ç›–å°ç½‘æ®µ)
    ip_raw.sort(key=lambda x: x[1].prefixlen) # æŒ‰æ©ç é•¿åº¦æ’åºï¼Œä¼˜å…ˆå¤„ç†å¤§ç½‘æ®µ
    kept_ip_nets, final_ip = [], []
    for rule_str, net in ip_raw:
        is_covered = False
        for k_net in kept_ip_nets:
            if k_net.supernet_of(net):
                is_covered = True
                log_logic.append(f"[é€»è¾‘è¦†ç›–] {rule_str:<40} # å·²è¢«å¤§ç½‘æ®µ {k_net} æ¶µç›–")
                break
        if not is_covered:
            final_ip.append(rule_str)
            kept_ip_nets.append(net)
        else: 
            stats['logic'] += 1

    # 6. ç¬¬å…­é˜¶æ®µï¼šè·¨ç±»å‹å»é‡ (æ£€æµ‹åŸŸåä¸­çš„ IP æ˜¯å¦åœ¨å·²æœ‰ç½‘æ®µä¸­)
    final_dom_clean = []
    for r_str in final_dom:
        v = r_str.split(',')[1]
        if re.match(r'^(\d{1,3}\.){3}\d{1,3}$', v): # å¦‚æœ DOMAIN é‡Œçš„å€¼æ˜¯çº¯ IP
            try:
                ip_obj = ipaddress.IPv4Address(v)
                if any(ip_obj in k_net for k_net in kept_ip_nets):
                    stats['logic'] += 1
                    log_logic.append(f"[é€»è¾‘è¦†ç›–] {r_str:<40} # è¯¥ IP å·²åœ¨ç½‘æ®µè§„åˆ™ä¸­")
                    continue
            except: pass
        final_dom_clean.append(r_str)

    res = final_dom_clean + final_suf + key_rules + final_ip + ip6_rules
    return res, stats, log_logic

def format_source_stats(source_stats):
    """æ ¼å¼åŒ–ç”Ÿæˆæºç»Ÿè®¡è¡¨"""
    max_name_len = max(len(s['name']) for s in source_stats)
    width = max(max_name_len, 10)
    lines = ["# " + "=" * (width + 25)]
    lines.append(f"# {'åç§°':<{width}} {'åŸå§‹è§„æ¨¡':>8} {'æå–æ¡æ•°':>8} {'æ— æ•ˆè¿‡æ»¤':>8}")
    lines.append("# " + "-" * (width + 25))
    for s in source_stats:
        lines.append(f"# {s['name']:<{width}} {s['raw']:>8} {s['valid']:>8} {s['raw']-s['valid']:>8}")
    lines.append("# " + "=" * (width + 25))
    return lines

def main():
    log("ğŸš€ å¯åŠ¨ Loon è§„åˆ™è‡ªåŠ¨åŒ–ä»»åŠ¡...", "INFO")
    session, all_rules, source_stats = create_session(), [], []
    total_start = time.time()

    # 1. åŒæ­¥æ•°æ®æº
    for idx, src in enumerate(RULE_SOURCES, 1):
        log(f"[{idx}/{len(RULE_SOURCES)}] æ­£åœ¨æ‹‰å–: {src['name']}")
        try:
            resp = session.get(src['url'], timeout=20)
            resp.raise_for_status()
            raw_lines = resp.text.splitlines()
            processed = []
            for l in raw_lines:
                l = l.strip()
                if not l or any(l.startswith(x) for x in ('#', '!', '[')): continue
                # è§„åˆ™é¢„å¤„ç†ï¼šå°†çº¯åŸŸåã€çº¯ç½‘æ®µè‡ªåŠ¨è½¬æ¢ä¸º Loon æ ¼å¼
                if re.match(r'^(\d{1,3}\.){3}\d{1,3}/\d{1,2}$', l): processed.append(f"IP-CIDR,{l}")
                elif re.match(r'^(\d{1,3}\.){3}\d{1,3}$', l): processed.append(f"DOMAIN,{l}")
                elif l.startswith('.'): processed.append(f"DOMAIN-SUFFIX,{l[1:]}")
                elif ',' not in l and is_valid_domain(l): processed.append(f"DOMAIN,{l}")
                else: processed.append(l)
            all_rules.extend(processed)
            source_stats.append({"name": src['name'], "raw": len(raw_lines), "valid": len(processed)})
        except Exception as e:
            log(f"åŒæ­¥å¤±è´¥: {src['name']} ({e})", "ERROR")

    # 2. æ‰§è¡Œç®—æ³•é€»è¾‘
    log("æ­£åœ¨åˆ†æåŸŸåå­—å…¸æ ‘ä¸ IP ç¢°æ’é€»è¾‘...", "INFO")
    final_list, stats, log_logic = dedup_engine(all_rules)
    
    # 3. å¯¹æœ€ç»ˆç»“æœè¿›è¡Œæ’åºï¼Œä½¿ç”Ÿæˆçš„è§„åˆ™æ•´æ´ç¾è§‚
    prio = {'DOMAIN': 1, 'DOMAIN-SUFFIX': 2, 'DOMAIN-KEYWORD': 3, 'IP-CIDR': 4, 'IP-CIDR6': 5}
    final_list.sort(key=lambda x: (prio.get(x.split(',')[0], 99), x.lower()))

    # 4. æ„å»ºæ–‡ä»¶å¤´éƒ¨æ³¨é‡Š
    header = [
        f"# Loon åˆºå®¢è§„åˆ™ (è‡ªåŠ¨åŒ–ç‰ˆ)",
        f"# ç”Ÿæˆæ—¶é—´: {get_beijing_time()}",
        f"# å‹ç¼©ä¼˜åŒ–: æ‹¦æˆªå±é™© {stats['danger']} | é€»è¾‘é‡å¤ {stats['logic']} | è·¨æºå®Œå…¨é‡å¤ {stats['exact']}",
        f"# è®¢é˜…åœ°å€: {SUBSCRIBE_URL}",
    ]
    header.extend(format_source_stats(source_stats))
    
    # 5. æŒä¹…åŒ–å­˜å‚¨
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        f.write('\n'.join(header) + '\n\n' + '\n'.join(final_list))
    
    # 6. ç”Ÿæˆè¿‡æ»¤æ—¥å¿—ï¼ˆä»…åŒ…å«é€»è¾‘è¿‡æ»¤ï¼Œé¡µå°¾æ˜¾ç¤ºå®Œå…¨é‡å¤æ•°ï¼‰
    with open(REMOVED_LOG_FILE, 'w', encoding='utf-8') as f:
        f.write(f"# Loon è¿‡æ»¤æ—¥å¿— - {get_beijing_time()}\n" + "="*80 + "\n")
        f.write(f"# é€»è¾‘è¿‡æ»¤æ€»æ•°: {len(log_logic)} æ¡ (è¯¦æƒ…å¦‚ä¸‹)\n")
        f.write(f"# å®Œå…¨é‡å¤æ€»æ•°: {stats['exact']} æ¡ (æ˜ç»†å·²çœç•¥)\n")
        f.write("="*80 + "\n\n")
        f.write('\n'.join(log_logic))
    
    log(f"âœ… ä»»åŠ¡æˆåŠŸï¼ç”Ÿæˆè§„åˆ™ {len(final_list)} æ¡ | è€—æ—¶ {time.time()-total_start:.1f}s", "OK")

if __name__ == "__main__":
    main()
