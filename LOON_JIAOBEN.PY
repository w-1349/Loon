#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import requests
import re
from datetime import datetime, timedelta

# â€”â€” æ ¸å¿ƒé…ç½®åŒº â€”â€”
RULE_SOURCES = [
    # å»ºè®®ä½¿ç”¨ raw é“¾æ¥
    {"name": "AdRules", "url": "https://raw.githubusercontent.com/Cats-Team/AdRules/main/adrules.list"},
    {"name": "anti-ad", "url": "https://anti-ad.net/surge2.txt"}
]
OUTPUT_FILE = "Loon_rules.txt"

def get_beijing_time():
    """è·å–åŒ—äº¬æ—¶é—´"""
    return (datetime.utcnow() + timedelta(hours=8)).strftime('%Y-%m-%d %H:%M:%S')

def is_valid_domain(domain):
    """
    æ ¡éªŒæ˜¯å¦ä¸ºçº¯å‡€åŸŸå
    æ’é™¤: IPåœ°å€ã€åŒ…å«/æˆ–^ç­‰ç‰¹æ®Šç¬¦å·çš„å­—ç¬¦ä¸²
    """
    if not domain: return False
    # å¿…é¡»åŒ…å«ç‚¹ï¼Œä¸”åªèƒ½ç”±å­—æ¯ã€æ•°å­—ã€ç‚¹ã€ä¸­åˆ’çº¿ç»„æˆ
    if '.' in domain and re.match(r'^[a-z0-9\-\.]+$', domain):
        # æ’é™¤ IP åœ°å€ (æœ€åä¸€æ®µæ˜¯æ•°å­—)
        if not domain.split('.')[-1].isdigit():
            return True
    return False

def process_line(line):
    """
    ã€ç²¾ç®€ç‰ˆåˆ†æ‹£é€»è¾‘ã€‘
    ä¸å¤„ç† AGH (||/@@) è¯­æ³•ï¼Œä¸¥æ ¼æ‰§è¡Œä¸‰æ¡è§„åˆ™
    """
    line = line.strip()
    
    # 1. åŸºç¡€è¿‡æ»¤ï¼šè·³è¿‡ç©ºè¡Œã€æ³¨é‡Š
    if not line or line.startswith(('!', '#', '[')):
        return None

    # ---------------------------------------------------------
    # è§„åˆ™ 1: åŸç”Ÿå¸¦æœ‰ DOMAIN æˆ– DOMAIN-SUFFIX å‰ç¼€ -> ä¿æŒä¸å˜
    # ---------------------------------------------------------
    upper_line = line.upper()
    if upper_line.startswith("DOMAIN-SUFFIX") or upper_line.startswith("DOMAIN"):
        return line

    # ---------------------------------------------------------
    # è§„åˆ™ 2: åŸç”Ÿå¸¦ . å¼€å¤´ -> æ›¿æ¢ä¸º DOMAIN-SUFFIX
    # ---------------------------------------------------------
    if line.startswith('.'):
        # å»æ‰å¼€å¤´çš„ç‚¹ï¼Œæ¸…æ´—å¹¶éªŒè¯
        clean_domain = line.lstrip('.').strip().lower()
        if is_valid_domain(clean_domain):
            return f"DOMAIN-SUFFIX,{clean_domain}"

    # ---------------------------------------------------------
    # è§„åˆ™ 3: æ— å‰ç¼€ä¸”æ˜¯åˆæ³•åŸŸå -> æ·»åŠ  DOMAIN
    # ---------------------------------------------------------
    # éªŒè¯æ•´è¡Œæ˜¯å¦ä¸ºä¸€ä¸ªå¹²å‡€çš„åŸŸå
    clean_domain = line.strip().lower()
    if is_valid_domain(clean_domain):
        return f"DOMAIN,{clean_domain}"

    # å…¶ä»–ä¸ç¬¦åˆæ ¼å¼çš„è¡Œï¼ˆåŒ…æ‹¬ || å¼€å¤´çš„ AGH è§„åˆ™ï¼‰å°†è¢«ä¸¢å¼ƒ
    return None

def main():
    all_rules = []
    source_stats = []
    
    print(f"[{get_beijing_time()}] ğŸš€ è„šæœ¬å¯åŠ¨ï¼šæ‰§è¡Œç²¾ç®€ç‰ˆåˆ†æ‹£é€»è¾‘ (æ— AGHè½¬æ¢)...")
    print("=" * 60)

    for src in RULE_SOURCES:
        try:
            print(f"ğŸ“¥ æ­£åœ¨æ‹‰å–: {src['name']}...")
            resp = requests.get(src['url'], timeout=30)
            resp.raise_for_status()
            lines = resp.text.splitlines()
            
            # å¤„ç†æ¯ä¸€è¡Œ
            processed_list = [r for r in (process_line(l) for l in lines) if r]
            
            # æºå†…å»é‡
            unique_src = list(dict.fromkeys(processed_list))
            
            print(f"   ğŸ“Š {src['name']} æ•°æ®:")
            print(f"      â”œâ”€ åŸå§‹è¡Œæ•°: {len(lines)}")
            print(f"      â””â”€ æœ‰æ•ˆæå–: {len(unique_src)}")
            
            source_stats.append({
                "name": src['name'], 
                "raw": len(lines), 
                "unique": len(unique_src)
            })
            all_rules.extend(unique_src)
            print(f"âœ… {src['name']} å¤„ç†å®Œæ¯•\n")

        except Exception as e:
            print(f"âŒ {src['name']} å¤±è´¥: {e}\n")

    print("=" * 60)
    print("ğŸ”„ æ­£åœ¨è¿›è¡Œå…¨å±€å»é‡ä¸åˆ†ç±»ç»Ÿè®¡...")
    
    # å…¨å±€å»é‡
    final_rules = sorted(list(set(all_rules)))
    final_total = len(final_rules)
    
    # â€”â€” æ ¸å¿ƒç»Ÿè®¡ï¼šåˆ†åˆ«è®¡ç®— DOMAIN å’Œ DOMAIN-SUFFIX â€”â€”
    count_domain = 0
    count_suffix = 0
    
    for rule in final_rules:
        # ç»Ÿä¸€è½¬å¤§å†™å‰ç¼€åˆ¤æ–­ï¼Œé˜²æ­¢æºæ–‡ä»¶å¤§å°å†™ä¸ä¸€è‡´
        upper_rule = rule.upper()
        if upper_rule.startswith('DOMAIN-SUFFIX'):
            count_suffix += 1
        elif upper_rule.startswith('DOMAIN'):
            count_domain += 1
            
    print(f"ğŸ“Š å…¨å±€ç»Ÿè®¡ç»“æœ:")
    print(f"   â”œâ”€ æ€»è§„åˆ™æ•°: {final_total}")
    print(f"   â”œâ”€ DOMAIN (ç²¾å‡†åŒ¹é…): {count_domain} æ¡")
    print(f"   â””â”€ DOMAIN-SUFFIX (åç¼€åŒ¹é…): {count_suffix} æ¡")

    # æ„å»ºæ–‡ä»¶å¤´
    header = [
        f"# Loon åŸŸåé›†åˆ (Lite Mode)",
        f"# ç”Ÿæˆæ—¶é—´: {get_beijing_time()}",
        f"# ç»Ÿè®¡æ‘˜è¦:",
        f"#   - æ€»æ¡æ•°: {final_total}",
        f"#   - DOMAIN: {count_domain}",
        f"#   - DOMAIN-SUFFIX: {count_suffix}",
        "# " + "="*58
    ]
    
    # æ·»åŠ åˆ†æºç»Ÿè®¡æ³¨é‡Š
    for s in source_stats:
        header.append(f"# æº: {s['name']} | åŸå§‹: {s['raw']} | æå–: {s['unique']}")
        
    header.append("# " + "="*58 + "\n")

    # å†™å…¥æ–‡ä»¶
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        f.write('\n'.join(header))
        f.write('\n'.join(final_rules))

    print(f"ğŸ’¾ æ–‡ä»¶å·²ä¿å­˜è‡³: {OUTPUT_FILE}")
    print(f"[{get_beijing_time()}] ğŸ‰ ä»»åŠ¡å®Œæˆï¼")

if __name__ == "__main__":
    main()
