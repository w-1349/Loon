#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import requests
import re
import time
import ipaddress
from datetime import datetime, timedelta
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

# ================= é…ç½®åŒº =================
RULE_SOURCES = [
    {"name": "AdRules", "url": "https://raw.githubusercontent.com/Cats-Team/AdRules/main/adrules.list"},
    {"name": "anti-ad", "url": "https://anti-ad.net/surge2.txt"},
    {"name": "ADG", "url": "https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/master/rule/Loon/Advertising/Advertising.list"},
    {"name": "ADG_Domain", "url": "https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/master/rule/Loon/Advertising/Advertising_Domain.list"},
    {"name": "Privacy", "url": "https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/master/rule/Loon/Privacy/Privacy.list"},
    {"name": "Privacy_Domain", "url": "https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/master/rule/Loon/Privacy/Privacy_Domain.list"},
]

OUTPUT_FILE = "Loon_rules.txt"
SUBSCRIBE_URL = "https://ddcm1349.github.io/Loon/Loon_rules.txt"

# å±é™©å…³é”®å­—/å…¬å…±åç¼€é»‘åå•ï¼ˆä¸¤æ­¥éªŒè¯ï¼šKeywordæŸ¥åŒ…å«ï¼ŒSuffixæŸ¥ç›¸ç­‰ï¼‰
INVALID_KEYWORDS = {
    'com', 'net', 'cn', 'org', 'io', 'co', 'tv', 'cc', 'app', 'dev',
    'com.cn', 'net.cn', 'org.cn', 'gov.cn', 'edu.cn', 'com.hk',
    'ads', 'api', 'cdn', 'static', 'www', 'download', 'upload'
}
# ==========================================

def get_beijing_time():
    return (datetime.utcnow() + timedelta(hours=8)).strftime('%Y-%m-%d %H:%M:%S')

def log(msg, level="INFO"):
    timestamp = get_beijing_time()
    prefix = {"INFO": "â„¹ï¸", "OK": "âœ…", "ERROR": "âŒ", "WARN": "âš ï¸", "DEBUG": "ğŸ”"}.get(level, "â€¢")
    print(f"[{timestamp}] {prefix} {msg}", flush=True)

def create_session():
    session = requests.Session()
    retries = Retry(total=3, backoff_factor=1, status_forcelist=[500, 502, 503, 504])
    session.mount("http://", HTTPAdapter(max_retries=retries))
    session.mount("https://", HTTPAdapter(max_retries=retries))
    session.headers.update({"User-Agent": "Mozilla/5.0 LoonRuleEngine/3.5"})
    return session

def is_valid_domain(domain):
    """ä¿®å¤ï¼šæ”¯æŒçº¯IPä½œä¸ºåŸŸå"""
    if not domain or len(domain) > 253: 
        return False
    if re.match(r'^(\d{1,3}\.){3}\d{1,3}$', domain):
        return True
    if not re.match(r'^[a-z0-9\-\.]+$', domain): 
        return False
    labels = domain.split('.')
    return len(labels) >= 2 and not labels[-1].isdigit()

def is_dangerous_keyword(rval):
    """ä¿®å¤ï¼šç²¾ç¡®çš„å•è¯è¾¹ç•Œæ£€æµ‹"""
    rval = rval.lower()
    for k in INVALID_KEYWORDS:
        if rval == k:
            return True
        if k in rval:
            idx = rval.find(k)
            before = rval[idx-1] if idx > 0 else ''
            after = rval[idx+len(k)] if idx+len(k) < len(rval) else ''
            if (not before or not before.isalnum()) and \
               (not after or not after.isalnum()):
                return True
    return False

def parse_loon_rule(line):
    """è§£æLoonè§„åˆ™ï¼Œè¿‡æ»¤ç©ºå‚æ•°"""
    parts = line.split(',')
    if len(parts) < 2: 
        return None
    params = [p.strip().lower() for p in parts[2:] if p.strip()]
    return (parts[0].strip().upper(), parts[1].strip(), params)

def normalize_rule_smart(rtype, rval, rparams):
    """
    æŒ‰ç”¨æˆ·éœ€æ±‚ï¼š
    - åŸŸåç±»ï¼šå‰”é™¤æ‰€æœ‰å‚æ•°
    - IPç±»ï¼šä»…ä¿ç•™ no-resolve
    """
    rval = rval.lower()
    if rtype in ("DOMAIN", "DOMAIN-SUFFIX", "DOMAIN-KEYWORD"):
        return f"{rtype},{rval}"
    if rtype in ("IP-CIDR", "IP-CIDR6"):
        if "no-resolve" in rparams:
            return f"{rtype},{rval},no-resolve"
        return f"{rtype},{rval}"
    return f"{rtype},{rval}"

def is_covered_by_trie(val, trie):
    """é«˜æ•ˆå­—å…¸æ ‘åŒ¹é…"""
    node = trie
    for part in val.split('.')[::-1]:
        if part not in node: 
            return False
        node = node[part]
        if "#" in node: 
            return True
    return False

def dedup_engine(rules):
    """æè‡´å»é‡å¼•æ“"""
    stats = {'danger': 0, 'logic': 0, 'exact': 0}
    seen = set()
    unique_base = []
    
    for r in rules:
        p = parse_loon_rule(r)
        if not p: 
            continue
        norm = normalize_rule_smart(*p)
        if norm not in seen:
            seen.add(norm)
            unique_base.append(p)
        else: 
            stats['exact'] += 1

    key_rules, suf_raw, dom_raw, ip_raw, ip6_rules = [], [], [], [], []

    for rtype, rval, rparams in unique_base:
        if rtype == 'DOMAIN-KEYWORD':
            if is_dangerous_keyword(rval):
                stats['danger'] += 1
                continue
            key_rules.append(f"{rtype},{rval}")
            
        elif rtype == 'DOMAIN-SUFFIX':
            if rval in INVALID_KEYWORDS:
                stats['danger'] += 1
                continue
            suf_raw.append((f"{rtype},{rval}", rval))
            
        elif rtype == 'DOMAIN':
            dom_raw.append((f"{rtype},{rval}", rval))
            
        elif rtype == 'IP-CIDR':
            try:
                net = ipaddress.IPv4Network(rval, strict=False)
                ip_raw.append((normalize_rule_smart(rtype, rval, rparams), net))
            except: 
                continue
                
        elif rtype == 'IP-CIDR6':
            ip6_rules.append(normalize_rule_smart(rtype, rval, rparams))

    # åŸŸåå»é‡
    suf_raw.sort(key=lambda x: len(x[1].split('.')))
    trie, final_suf = {}, []
    for rule_str, val in suf_raw:
        if not is_covered_by_trie(val, trie):
            final_suf.append(rule_str)
            node = trie
            for part in val.split('.')[::-1]: 
                node = node.setdefault(part, {})
            node["#"] = True
        else: 
            stats['logic'] += 1

    final_dom = []
    for r, v in dom_raw:
        if is_covered_by_trie(v, trie): 
            stats['logic'] += 1
        else: 
            final_dom.append(r)

    # IPå»é‡
    ip_raw.sort(key=lambda x: x[1].prefixlen)
    kept_ip_nets, final_ip = [], []
    for rule_str, net in ip_raw:
        if not any(k_net.supernet_of(net) for k_net in kept_ip_nets):
            final_ip.append(rule_str)
            kept_ip_nets.append(net)
        else: 
            stats['logic'] += 1

    # è·¨ç±»å‹å»é‡
    final_dom_clean = []
    for r_str in final_dom:
        parts = r_str.split(',')
        if len(parts) < 2:
            final_dom_clean.append(r_str)
            continue
        v = parts[1]
        if re.match(r'^(\d{1,3}\.){3}\d{1,3}$', v):
            try:
                ip_obj = ipaddress.IPv4Address(v)
                if any(ip_obj in k_net for k_net in kept_ip_nets):
                    stats['logic'] += 1
                    continue
            except:
                pass
        final_dom_clean.append(r_str)

    res = final_dom_clean + final_suf + key_rules + final_ip + ip6_rules
    return res, stats

def format_source_stats(source_stats):
    """æ ¼å¼åŒ–æºç»Ÿè®¡"""
    max_name_len = max(len(s['name']) for s in source_stats)
    width = max(max_name_len, 10)
    lines = ["# " + "=" * (width + 25)]
    lines.append(f"# {'åç§°':<{width}} {'åŸå§‹':>8} {'æå–':>8} {'ä¸¢å¼ƒ':>8}")
    lines.append("# " + "-" * (width + 25))
    for s in source_stats:
        lines.append(f"# {s['name']:<{width}} {s['raw']:>8} {s['valid']:>8} {s['raw']-s['valid']:>8}")
    lines.append("# " + "=" * (width + 25))
    return lines

def format_type_stats(final_list):
    """æ–°å¢ï¼šç»Ÿè®¡å„ç±»å‹è§„åˆ™æ•°é‡"""
    type_count = {}
    for rule in final_list:
        rtype = rule.split(',')[0] if ',' in rule else 'UNKNOWN'
        type_count[rtype] = type_count.get(rtype, 0) + 1
    
    # æŒ‰ä¼˜å…ˆçº§æ’åº
    prio_order = ['DOMAIN', 'DOMAIN-SUFFIX', 'DOMAIN-KEYWORD', 'IP-CIDR', 'IP-CIDR6', 'UNKNOWN']
    lines = ["# ç±»å‹åˆ†å¸ƒç»Ÿè®¡:"]
    total = len(final_list)
    
    for t in prio_order:
        if t in type_count:
            count = type_count[t]
            pct = count / total * 100 if total > 0 else 0
            lines.append(f"#   {t:<15} {count:>6} æ¡ ({pct:>5.1f}%)")
    
    lines.append("# " + "-" * 30)
    lines.append(f"#   {'TOTAL':<15} {total:>6} æ¡")
    return lines

def main():
    log("ğŸš€ å¯åŠ¨è§„åˆ™æŠ“å–ä»»åŠ¡...", "INFO")
    session, all_rules, source_stats = create_session(), [], []
    total_start = time.time()

    for idx, src in enumerate(RULE_SOURCES, 1):
        log(f"[{idx}/{len(RULE_SOURCES)}] æ­£åœ¨è¯·æ±‚: {src['name']}")
        try:
            resp = session.get(src['url'], timeout=20)
            resp.raise_for_status()
            raw_lines = resp.text.splitlines()
            processed = []
            for l in raw_lines:
                l = l.strip()
                if not l or any(l.startswith(x) for x in ('#', '!', '[')): 
                    continue
                
                if re.match(r'^(\d{1,3}\.){3}\d{1,3}/\d{1,2}$', l): 
                    processed.append(f"IP-CIDR,{l}")
                elif re.match(r'^(\d{1,3}\.){3}\d{1,3}$', l): 
                    processed.append(f"DOMAIN,{l}")
                elif l.startswith('.'): 
                    processed.append(f"DOMAIN-SUFFIX,{l[1:]}")
                elif ',' not in l and is_valid_domain(l): 
                    processed.append(f"DOMAIN,{l}")
                else: 
                    processed.append(l)

            all_rules.extend(processed)
            source_stats.append({"name": src['name'], "raw": len(raw_lines), "valid": len(processed)})
            log(f"    å®Œæˆ: æå– {len(processed)} æ¡", "OK")
        except Exception as e:
            log(f"    å¤±è´¥: {src['name']} ({e})", "ERROR")

    log("æ¸…ç†å†—ä½™é€»è¾‘ä¸­...", "INFO")
    final_list, stats = dedup_engine(all_rules)
    
    # æ’åº
    prio = {'DOMAIN': 1, 'DOMAIN-SUFFIX': 2, 'DOMAIN-KEYWORD': 3, 'IP-CIDR': 4, 'IP-CIDR6': 5}
    final_list.sort(key=lambda x: (prio.get(x.split(',')[0], 99), x.lower()))

    # æ„å»ºå¤´éƒ¨ï¼ˆæ–°å¢ç±»å‹ç»Ÿè®¡ï¼‰
    header = [
        f"# Loon_ADåˆºå®¢ (ä¿®å¤ä¼˜åŒ–ç‰ˆ v3.7)",
        f"# ç”Ÿæˆæ—¶é—´: {get_beijing_time()}",
        f"# è§„åˆ™ç»Ÿè®¡: {len(final_list)} æ¡",
        f"# å‹ç¼©ä¼˜åŒ–: å‰”é™¤å±é™© {stats['danger']} | é€»è¾‘é‡å¤ {stats['logic']} | å®Œå…¨é‡å¤ {stats['exact']}",
        f"# è®¢é˜…åœ°å€: {SUBSCRIBE_URL}",
    ]
    header.extend(format_source_stats(source_stats))
    # æ–°å¢ï¼šç±»å‹åˆ†å¸ƒç»Ÿè®¡
    header.extend(format_type_stats(final_list))
    
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        f.write('\n'.join(header) + '\n\n' + '\n'.join(final_list))
    
    log(f"ä»»åŠ¡å®Œæˆï¼ä¿å­˜è‡³ {OUTPUT_FILE}ï¼Œæ€»è€—æ—¶ {time.time()-total_start:.1f}s", "OK")

if __name__ == "__main__":
    main()
