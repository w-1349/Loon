#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import requests
import re
from datetime import datetime, timedelta

# â€”â€” æ ¸å¿ƒé…ç½®åŒº â€”â€”
RULE_SOURCES = [
    {"name": "AdRules", "url": "https://raw.githubusercontent.com/Cats-Team/AdRules/main/adrules.list"},
    {"name": "anti-ad", "url": "https://anti-ad.net/surge2.txt"}
]
OUTPUT_FILE = "Loon_rules.txt"

def get_beijing_time():
    """ç”ŸæˆåŒ—äº¬æ—¶é—´å­—ç¬¦ä¸²"""
    return (datetime.utcnow() + timedelta(hours=8)).strftime('%Y-%m-%d %H:%M:%S')

def process_line(line):
    """
    åˆ†æ‹£é€»è¾‘ï¼š
    1. å¸¦ '.' å¼€å¤´ -> DOMAIN-SUFFIX
    2. ä¸å¸¦ '.' å¼€å¤´ -> DOMAIN
    """
    line = line.strip()
    if not line or line.startswith(('#', '!', '[')) or '/' in line or '$' in line:
        return None

    is_suffix = line.startswith('.')
    raw_domain = line
    
    if ',' in line:
        parts = line.split(',')
        for p in parts:
            p = p.strip()
            if '.' in p and not p.isupper():
                raw_domain = p
                break

    clean_domain = raw_domain.lstrip('.').lower().split('^')[0].split(':')[0]

    if '.' in clean_domain and re.match(r'^[a-z0-9\-\.]+$', clean_domain):
        if not clean_domain.split('.')[-1].isdigit():
            return f"DOMAIN-SUFFIX,{clean_domain}" if is_suffix else f"DOMAIN,{clean_domain}"
            
    return None

def main():
    all_rules = []
    source_stats = []
    
    print(f"[{get_beijing_time()}] ğŸš€ ä»»åŠ¡å¯åŠ¨ï¼šæ‰§è¡Œåˆ†æ‹£ä¸è¯¦ç»†ç»Ÿè®¡...")
    print("=" * 60)

    for src in RULE_SOURCES:
        try:
            print(f"ğŸ“¥ æ­£åœ¨æ‹‰å–: {src['name']}...")
            resp = requests.get(src['url'], timeout=30)
            resp.raise_for_status()
            lines = resp.text.splitlines()
            
            raw_count = len(lines)
            temp_list = [r for r in (process_line(l) for l in lines) if r]
            unique_src = list(dict.fromkeys(temp_list))
            
            print(f"   ğŸ“Š {src['name']} ç»Ÿè®¡:")
            print(f"      â”œâ”€ åŸå§‹è¡Œæ•°: {raw_count}")
            print(f"      â””â”€ æœ‰æ•ˆå»é‡: {len(unique_src)}")
            
            source_stats.append({"name": src['name'], "raw": raw_count, "unique": len(unique_src)})
            all_rules.extend(unique_src)
            print(f"âœ… {src['name']} å¤„ç†å®Œæ¯•\n")

        except Exception as e:
            print(f"âŒ {src['name']} å‡ºé”™: {e}\n")

    print("=" * 60)
    print("ğŸ”„ æ­£åœ¨è¿›è¡Œå…¨å±€å»é‡ä¸ç±»å‹æ±‡æ€»...")
    
    # å…¨å±€å»é‡
    final_rules = sorted(list(set(all_rules)))
    
    # æ ¸å¿ƒç»Ÿè®¡ï¼šè®¡ç®— DOMAIN å’Œ DOMAIN-SUFFIX çš„æ•°é‡
    do_count = sum(1 for r in final_rules if r.startswith("DOMAIN,"))
    su_count = sum(1 for r in final_rules if r.startswith("DOMAIN-SUFFIX,"))
    final_count = len(final_rules)

    print(f"ğŸ“Š å…¨å±€åˆå¹¶ç»“æœ:")
    print(f"   â”œâ”€ æœ€ç»ˆæ€»æ¡æ•°: {final_count}")
    print(f"   â”œâ”€ DOMAIN (ç²¾å‡†åŒ¹é…): {do_count}")
    print(f"   â””â”€ DOMAIN-SUFFIX (åç¼€åŒ¹é…): {su_count}")

    # å†™å…¥æ–‡ä»¶
    header = [
        f"# Loon åŸŸåé›†åˆ (ç²¾ç»†ç»Ÿè®¡ç‰ˆ)",
        f"# ç”Ÿæˆæ—¶é—´: {get_beijing_time()}",
        f"# æœ€ç»ˆæ€»æ¡æ•°: {final_count}",
        f"# å…¶ä¸­ DOMAIN: {do_count} æ¡",
        f"# å…¶ä¸­ DOMAIN-SUFFIX: {su_count} æ¡",
        "# " + "="*58
    ]
    for s in source_stats:
        header.append(f"# æº: {s['name']} | åŸå§‹: {s['raw']} | æœ‰æ•ˆ: {s['unique']}")
    header.append("# " + "="*58 + "\n")

    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        f.write('\n'.join(header))
        f.write('\n'.join(final_rules))

    print("=" * 60)
    print(f"ğŸ’¾ æ–‡ä»¶å·²ä¿å­˜: {OUTPUT_FILE}")
    print(f"[{get_beijing_time()}] ğŸ‰ ç»Ÿè®¡ä»»åŠ¡åœ†æ»¡å®Œæˆï¼")

if __name__ == "__main__":
    main()
