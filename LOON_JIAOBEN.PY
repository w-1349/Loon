#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import requests
import re
from datetime import datetime, timedelta

# è§„åˆ™æºé…ç½®åˆ—è¡¨ï¼ŒæŒ‰ä¼˜å…ˆçº§æ’åº
RULE_SOURCES = [
    {"name": "AdRules", "url": "https://raw.githubusercontent.com/Cats-Team/AdRules/main/adrules.list"},
    {"name": "anti-ad", "url": "https://anti-ad.net/surge2.txt"},
    {"name": "Advertising", "url": "https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/master/rule/Loon/Advertising/Advertising.list"},
    {"name": "Advertising_Domain", "url": "https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/master/rule/Loon/Advertising/Advertising_Domain.list"},
    {"name": "Privacy", "url": "https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/master/rule/Loon/Privacy/Privacy.list"},
    {"name": "Privacy_Domain", "url": "https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/master/rule/Loon/Privacy/Privacy_Domain.list"},
]

# è¾“å‡ºæ–‡ä»¶è·¯å¾„
OUTPUT_FILE = "Loon_rules.txt"
# è®¢é˜…åœ°å€æ˜¾ç¤º
SUBSCRIBE_URL = "https://ddcm1349.github.io/Loon/Loon_rules.txt"


def get_beijing_time():
    """è·å–å¹¶æ ¼å¼åŒ–å½“å‰åŒ—äº¬æ—¶é—´"""
    utc_now = datetime.utcnow()
    beijing_time = utc_now + timedelta(hours=8) # UTC+8
    return beijing_time.strftime('%Y-%m-%d %H:%M:%S')


def is_valid_domain(domain):
    """éªŒè¯åŸŸåæ ¼å¼åˆæ³•æ€§"""
    if not domain or len(domain) > 253: return False
    if not re.match(r'^[a-z0-9\-\.]+$', domain): return False # åªå…è®¸åˆæ³•å­—ç¬¦
    if '..' in domain or domain.startswith('.') or domain.endswith('.'): return False
    labels = domain.split('.')
    if len(labels) < 2: return False # è‡³å°‘è¦æœ‰äºŒçº§åŸŸå
    for label in labels:
        if not 1 <= len(label) <= 63 or label.startswith('-') or label.endswith('-'):
            return False
    if labels[-1].isdigit(): return False # é¡¶çº§åŸŸåä¸èƒ½æ˜¯æ•°å­—
    return True


def is_valid_ip_cidr(ip_str):
    """éªŒè¯IPv4 CIDRæ ¼å¼"""
    pattern = r'^(\d{1,3}\.){3}\d{1,3}/\d{1,2}$'
    if not re.match(pattern, ip_str): return False
    try:
        ip_part, mask_part = ip_str.split('/')
        mask = int(mask_part)
        if not (0 <= mask <= 32): return False
        return all(0 <= int(part) <= 255 for part in ip_part.split('.'))
    except: return False


def is_valid_ip_cidr6(ip_str):
    """éªŒè¯IPv6 CIDRæ ¼å¼"""
    if '/' not in ip_str: return False
    try:
        ip_part, mask_part = ip_str.rsplit('/', 1)
        mask = int(mask_part)
        return 0 <= mask <= 128 and ':' in ip_part
    except: return False


def is_valid_pure_ip(ip_str):
    """éªŒè¯çº¯IPv4åœ°å€æ ¼å¼"""
    if '/' in ip_str or not re.match(r'^[\d\.]+$', ip_str): return False
    parts = ip_str.split('.')
    if len(parts) != 4: return False
    try:
        return all(0 <= int(p) <= 255 and not (len(p)>1 and p[0]=='0') for p in parts)
    except: return False


def is_loon_format(line):
    """æ£€æŸ¥æ˜¯å¦å·²ç»æ˜¯Loonæ ‡å‡†çš„è§„åˆ™å‰ç¼€"""
    prefixes = ('DOMAIN,', 'DOMAIN-SUFFIX,', 'DOMAIN-KEYWORD,', 'IP-CIDR,', 'IP-CIDR6,')
    return any(line.upper().startswith(p) for p in prefixes)


def parse_loon_rule(line):
    """è§£æLoonè§„åˆ™è¡Œï¼Œæ‹†åˆ†ä¸ºç±»å‹ã€å€¼ã€å‚æ•°"""
    parts = line.split(',')
    if len(parts) < 2: return None
    rule_type = parts[0].strip().upper()
    value = parts[1].strip()
    params = [p.strip() for p in parts[2:]] if len(parts) > 2 else []
    return (rule_type, value, params)


def normalize_rule(rule_type, value, params):
    """ç»Ÿä¸€è§„èŒƒåŒ–è§„åˆ™è¾“å‡ºï¼Œä¿æŒno-resolveåœ¨æœ€å"""
    other_params = [p for p in params if p.lower() != 'no-resolve']
    has_no_resolve = any(p.lower() == 'no-resolve' for p in params)
    if has_no_resolve: other_params.append('no-resolve')
    return f"{rule_type},{value},{','.join(other_params)}" if other_params else f"{rule_type},{value}"


def process_loon_line(line):
    """è¯¦ç»†æ ¡éªŒå¹¶å¤„ç†Loonæ ¼å¼è§„åˆ™"""
    parsed = parse_loon_rule(line)
    if not parsed: return None
    rule_type, value, params = parsed
    if rule_type in ('DOMAIN', 'DOMAIN-SUFFIX'):
        if not is_valid_pure_ip(value) and not is_valid_domain(value): return None
    elif rule_type == 'IP-CIDR' and not is_valid_ip_cidr(value): return None
    return normalize_rule(rule_type, value, params)


def process_line_smart(line):
    """æ™ºèƒ½è¯†åˆ«éæ ‡æ ¼å¼å¹¶è½¬æ¢ä¸ºLoonæ ‡å‡†"""
    line = line.strip()
    if not line or any(line.startswith(x) for x in ('#', '!', '[')): return None
    if is_loon_format(line): return process_loon_line(line)
    if is_valid_ip_cidr(line): return f"IP-CIDR,{line}"
    if is_valid_ip_cidr6(line): return f"IP-CIDR6,{line}"
    if is_valid_pure_ip(line): return f"DOMAIN,{line}"
    if line.startswith('.'): # å¤„ç† .example.com æ ¼å¼
        d = line[1:].lower()
        return f"DOMAIN-SUFFIX,{d}" if is_valid_domain(d) else None
    d = line.lower()
    return f"DOMAIN,{d}" if is_valid_domain(d) else None


def get_rule_key(rule):
    """ç”Ÿæˆå”¯ä¸€é”®ç”¨äºå½»åº•å»é‡"""
    p = parse_loon_rule(rule)
    if not p: return rule
    return (p[0], p[1].lower(), tuple(sorted([x.lower() for x in p[2]])))


def get_rule_priority(rule):
    """å®šä¹‰è¾“å‡ºæ—¶çš„æ’åºä¼˜å…ˆçº§"""
    p = parse_loon_rule(rule)
    priority_map = {'DOMAIN': 1, 'DOMAIN-SUFFIX': 2, 'DOMAIN-KEYWORD': 3, 'IP-CIDR': 4, 'IP-CIDR6': 5}
    return priority_map.get(p[0] if p else '', 99)


def ip_to_int(ip_str):
    """IPv4è½¬æ•´æ•°ï¼Œä¾¿äºè®¡ç®—ç½‘æ®µåŒ…å«å…³ç³»"""
    try:
        parts = ip_str.split('.')
        return (int(parts[0]) << 24) + (int(parts[1]) << 16) + (int(parts[2]) << 8) + int(parts[3])
    except: return None


def dedup_rules(rules):
    """
    æ ¸å¿ƒå»é‡ä¼˜åŒ–å‡½æ•°ï¼ˆæ€§èƒ½è¡¥ä¸ç‰ˆï¼‰
    """
    # 1. å®Œå…¨ç›¸åŒè§„åˆ™å»é‡
    seen_keys = {}
    unique_rules = []
    dup_removed = 0
    for rule in rules:
        key = get_rule_key(rule)
        if key not in seen_keys:
            seen_keys[key] = True
            unique_rules.append(rule)
        else: dup_removed += 1
    
    # åˆ†ç±»å­˜æ”¾ä»¥ä¾¿åç»­é€»è¾‘åˆ¤æ–­
    ip_cidr_list = []
    ip_cidr6_list = []
    domain_list = []
    suffix_list = []
    keyword_list = []
    
    for rule in unique_rules:
        p = parse_loon_rule(rule)
        if not p: continue
        rtype, rval = p[0], p[1].lower()
        if rtype == 'IP-CIDR':
            ip_s, mask_s = rval.split('/')
            ip_cidr_list.append((ip_to_int(ip_s), int(mask_s), rule))
        elif rtype == 'IP-CIDR6': ip_cidr6_list.append(rule)
        elif rtype == 'DOMAIN': domain_list.append((rval, rule))
        elif rtype == 'DOMAIN-SUFFIX': suffix_list.append((rval, rule))
        elif rtype == 'DOMAIN-KEYWORD': keyword_list.append(rule)

    # 2. IP-CIDR åŒ…å«å»é‡ï¼ˆå¤§ç½‘æ®µå‰”é™¤å°ç½‘æ®µï¼‰
    ip_cidr_list.sort(key=lambda x: x[1]) # æŒ‰æ©ç ä»å°åˆ°å¤§æ’
    kept_ip = []
    ip_removed = 0
    for ip_int, mask, rule in ip_cidr_list:
        is_covered = False
        for k_ip, k_mask, _ in kept_ip:
            if (ip_int >> (32-k_mask)) == (k_ip >> (32-k_mask)):
                is_covered = True; break
        if is_covered: ip_removed += 1
        else: kept_ip.append((ip_int, mask, rule))

    # 3. åç¼€åŒ…å«å»é‡ï¼ˆæ€§èƒ½æ ¸å¿ƒï¼šä½¿ç”¨HashæŸ¥æ‰¾ä»£æ›¿å…¨é‡æ‰«æï¼‰
    suffix_list = [(d, r) for d, r in suffix_list if len(d.split('.')) >= 2]
    suffix_list.sort(key=lambda x: len(x[0].split('.'))) # çŸ­åŸŸååœ¨å‰
    kept_suffix_set = set() # è®°å½•å·²ä¿ç•™çš„åŸŸåé›†åˆ
    final_suffixes = []
    suffix_removed = 0
    for domain, rule in suffix_list:
        parts = domain.split('.')
        is_redun = False
        # ä»å½“å‰åŸŸåçš„ä¸Šä¸€çº§å¼€å§‹å‘ä¸Šé€çº§æ£€æŸ¥
        for i in range(1, len(parts) - 1):
            parent = '.'.join(parts[i:])
            if parent in kept_suffix_set: # O(1) æ•ˆç‡æŸ¥æ‰¾
                is_redun = True; break
        if is_redun: suffix_removed += 1
        else:
            kept_suffix_set.add(domain)
            final_suffixes.append(rule)

    # 4. åŸŸåè¢«åç¼€åŒ…å«å»é‡
    final_domains = []
    dom_in_suf_removed = 0
    for domain, rule in domain_list:
        parts = domain.split('.')
        is_cov = False
        # æ£€æŸ¥è¯¥åŸŸåçš„ä»»ä¸€çº§åç¼€æ˜¯å¦å·²åœ¨æ‹¦æˆªåˆ—è¡¨ä¸­
        for i in range(len(parts) - 1):
            suf = '.'.join(parts[i:])
            if suf in kept_suffix_set:
                is_cov = True; break
        if is_cov: dom_in_suf_removed += 1
        else: final_domains.append((domain, rule))

    # 5. è·¨ç±»å‹å»é‡ï¼šçº¯IPåŸŸåè¢«IP-CIDRè¦†ç›–æ£€æŸ¥
    final_dom_rules = []
    cross_removed = 0
    for domain, rule in final_domains:
        ip_v = ip_to_int(domain)
        is_ip_cov = False
        if ip_v is not None:
            for k_ip, k_mask, _ in kept_ip:
                if (ip_v >> (32-k_mask)) == (k_ip >> (32-k_mask)):
                    is_ip_cov = True; break
        if is_ip_cov: cross_removed += 1
        else: final_dom_rules.append(rule)

    # åˆå¹¶æ‰€æœ‰åˆ†ç±»å¥½çš„è§„åˆ™
    final_rules = final_dom_rules + final_suffixes + keyword_list + [r for _,_,r in kept_ip] + ip_cidr6_list
    total_removed = dup_removed + ip_removed + suffix_removed + dom_in_suf_removed + cross_removed
    return final_rules, total_removed


def main():
    print(f"[{get_beijing_time()}] ğŸš€ è„šæœ¬å¯åŠ¨")
    all_rules = []
    source_stats = []
    
    for src in RULE_SOURCES:
        try:
            print(f"ğŸ“¥ æŠ“å–æº: {src['name']}...", flush=True)
            resp = requests.get(src['url'], timeout=30)
            resp.raise_for_status()
            lines = resp.text.splitlines()
            processed = [r for r in (process_line_smart(l) for l in lines) if r]
            
            # æºå†…åˆæ­¥å»é‡ç»Ÿè®¡
            seen = set()
            unique_src = []
            for r in processed:
                if r not in seen:
                    seen.add(r); unique_src.append(r)
            
            source_stats.append({"name": src['name'], "raw": len(lines), "valid": len(unique_src)})
            all_rules.extend(unique_src)
            print(f"   æå–æˆåŠŸ: {len(unique_src)} æ¡")
        except Exception as e:
            print(f"âŒ æŠ“å–å¤±è´¥: {src['name']} -> {e}")

    print(f"ğŸ”„ å¼€å§‹å…¨å±€ä¼˜åŒ–ä¸å»é‡...", flush=True)
    final, removed_count = dedup_rules(all_rules)
    final.sort(key=lambda r: (get_rule_priority(r), r.lower()))

    # æ„å»ºæ±‡æ€»å¤´éƒ¨
    header = [
        f"# Loon_ADåˆºå®¢",
        f"# ç”Ÿæˆæ—¶é—´: {get_beijing_time()}",
        f"# ç»Ÿè®¡: {len(final)} æ¡",
        f"# ä¼˜åŒ–: ç§»é™¤ {removed_count} æ¡å†—ä½™è§„åˆ™",
        f"# è®¢é˜…åœ°å€: {SUBSCRIBE_URL}",
        "# " + "="*58
    ]
    for s in source_stats:
        header.append(f"# æº: {s['name']} | åŸå§‹ {s['raw']} | æå– {s['valid']}")
    
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        f.write('\n'.join(header) + '\n\n' + '\n'.join(final))
    
    print(f"[{get_beijing_time()}] ğŸ‰ ä»»åŠ¡åœ†æ»¡å®Œæˆï¼")

if __name__ == "__main__":
    main()
