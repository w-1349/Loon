#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import requests
import re
import time
from datetime import datetime, timedelta

# è§„åˆ™æºé…ç½®
RULE_SOURCES = [
    {"name": "AdRules", "url": "https://raw.githubusercontent.com/Cats-Team/AdRules/main/adrules.list"},
    {"name": "anti-ad", "url": "https://anti-ad.net/surge2.txt"},
    {"name": "ADG", "url": "https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/master/rule/Loon/Advertising/Advertising.list"},
    {"name": "ADG_Domain", "url": "https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/master/rule/Loon/Advertising/Advertising_Domain.list"},
    {"name": "Privacy", "url": "https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/master/rule/Loon/Privacy/Privacy.list"},
    {"name": "Privacy_Domain", "url": "https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/master/rule/Loon/Privacy/Privacy_Domain.list"},
]

OUTPUT_FILE = "Loon_rules.txt"
SUBSCRIBE_URL = "https://ddcm1349.github.io/Loon/Loon_rules.txt"

# é‡è¯•é…ç½®
MAX_RETRIES = 3
RETRY_DELAYS = [1, 2, 4]


def get_beijing_time():
    """è·å–åŒ—äº¬æ—¶é—´"""
    utc_now = datetime.utcnow()
    beijing_time = utc_now + timedelta(hours=8)
    return beijing_time.strftime('%Y-%m-%d %H:%M:%S')


def log(msg, level="INFO"):
    """è¾“å‡ºæ—¥å¿—å¸¦æ—¶é—´æˆ³"""
    timestamp = get_beijing_time()
    prefix = {"INFO": "â„¹ï¸", "OK": "âœ…", "ERROR": "âŒ", "WARN": "âš ï¸", "DEBUG": "ğŸ”"}.get(level, "â€¢")
    print(f"[{timestamp}] {prefix} {msg}", flush=True)


def is_valid_domain(domain):
    """æ ¡éªŒåŸŸåæ ¼å¼"""
    if not domain or len(domain) > 253:
        return False
    if not re.match(r'^[a-z0-9\-\.]+$', domain):
        return False
    if '..' in domain or domain.startswith('.') or domain.endswith('.'):
        return False
    labels = domain.split('.')
    if len(labels) < 2:
        return False
    for label in labels:
        if not 1 <= len(label) <= 63:
            return False
        if label.startswith('-') or label.endswith('-'):
            return False
    return not labels[-1].isdigit()


def is_valid_ip_cidr(ip_str):
    """æ ¡éªŒIPv4 CIDR"""
    pattern = r'^(\d{1,3}\.){3}\d{1,3}/\d{1,2}$'
    if not re.match(pattern, ip_str):
        return False
    try:
        ip_part, mask_part = ip_str.split('/')
        return 0 <= int(mask_part) <= 32 and all(0 <= int(p) <= 255 for p in ip_part.split('.'))
    except:
        return False


def is_valid_ip_cidr6(ip_str):
    """æ ¡éªŒIPv6 CIDR"""
    if '/' not in ip_str:
        return False
    try:
        ip_part, mask_part = ip_str.rsplit('/', 1)
        return 0 <= int(mask_part) <= 128 and ':' in ip_part
    except:
        return False


def is_valid_pure_ip(ip_str):
    """æ ¡éªŒçº¯IPv4"""
    if '/' in ip_str or not re.match(r'^[\d\.]+$', ip_str):
        return False
    parts = ip_str.split('.')
    if len(parts) != 4:
        return False
    try:
        return all(0 <= int(p) <= 255 and not (len(p) > 1 and p[0] == '0') for p in parts)
    except:
        return False


def parse_loon_rule(line):
    """è§£æLoonè§„åˆ™è¡Œ"""
    parts = line.split(',')
    if len(parts) < 2:
        return None
    return (parts[0].strip().upper(), parts[1].strip(), [p.strip() for p in parts[2:]])


def normalize_rule(rule_type, value, params):
    """è§„èŒƒåŒ–å‚æ•°"""
    other = [p for p in params if p.lower() != 'no-resolve']
    if any(p.lower() == 'no-resolve' for p in params):
        other.append('no-resolve')
    return f"{rule_type},{value},{','.join(other)}" if other else f"{rule_type},{value}"


def process_line_smart(line):
    """æ™ºèƒ½è½¬æ¢æ ¼å¼"""
    line = line.strip()
    if not line or any(line.startswith(x) for x in ('#', '!', '[')):
        return None
    
    prefixes = ('DOMAIN,', 'DOMAIN-SUFFIX,', 'DOMAIN-KEYWORD,', 'IP-CIDR,', 'IP-CIDR6,')
    
    if any(line.upper().startswith(p) for p in prefixes):
        p = parse_loon_rule(line)
        if not p:
            return None
        rtype, rval, rparams = p
        if rtype in ('DOMAIN', 'DOMAIN-SUFFIX', 'DOMAIN-KEYWORD'):
            rparams = [x for x in rparams if x.lower() != 'no-resolve']
        return normalize_rule(rtype, rval, rparams)
    
    if is_valid_ip_cidr(line):
        return f"IP-CIDR,{line}"
    
    if is_valid_ip_cidr6(line):
        return f"IP-CIDR6,{line}"
    
    if is_valid_pure_ip(line):
        return f"DOMAIN,{line}"
    
    if line.startswith('.'):
        d = line[1:].lower()
        return f"DOMAIN-SUFFIX,{d}" if is_valid_domain(d) else None
    
    d = line.lower()
    return f"DOMAIN,{d}" if is_valid_domain(d) else None


def ip_to_int(ip_str):
    """IPè½¬æ•´æ•°ï¼Œå¢åŠ é•¿åº¦æ£€æŸ¥é˜²æ­¢IndexError"""
    try:
        parts = ip_str.split('.')
        # å®‰å…¨æ£€æŸ¥ï¼šå¿…é¡»ä¸º4æ®µ
        if len(parts) != 4:
            return None
        return (int(parts[0]) << 24) + (int(parts[1]) << 16) + (int(parts[2]) << 8) + int(parts[3])
    except:
        return None


def fetch_with_retry(url, name):
    """å¸¦é‡è¯•æœºåˆ¶çš„HTTPè¯·æ±‚"""
    headers = {'User-Agent': 'Mozilla/5.0 (compatible; RuleFetcher/1.0)'}
    
    for attempt in range(MAX_RETRIES):
        try:
            start_time = time.time()
            resp = requests.get(url, timeout=30, headers=headers)
            resp.raise_for_status()
            elapsed = time.time() - start_time
            
            content_length = len(resp.content)
            lines_count = len(resp.text.splitlines())
            
            log(f"ä¸‹è½½æˆåŠŸ: {content_length/1024:.1f}KB, {lines_count} è¡Œ, è€—æ—¶ {elapsed:.2f}s", "DEBUG")
            return resp.text, lines_count, None
            
        except requests.exceptions.Timeout:
            error_msg = f"è¿æ¥è¶…æ—¶ (attempt {attempt + 1}/{MAX_RETRIES})"
            log(error_msg, "WARN")
        except requests.exceptions.ConnectionError as e:
            error_msg = f"è¿æ¥é”™è¯¯: {str(e)[:50]} (attempt {attempt + 1}/{MAX_RETRIES})"
            log(error_msg, "WARN")
        except requests.exceptions.HTTPError as e:
            error_msg = f"HTTPé”™è¯¯ {e.response.status_code}: {str(e)[:50]}"
            log(error_msg, "ERROR")
            if 400 <= e.response.status_code < 500:
                return None, 0, error_msg
        except Exception as e:
            error_msg = f"æœªçŸ¥é”™è¯¯: {str(e)[:50]} (attempt {attempt + 1}/{MAX_RETRIES})"
            log(error_msg, "WARN")
        
        if attempt < MAX_RETRIES - 1:
            delay = RETRY_DELAYS[attempt]
            log(f"{delay}ç§’åé‡è¯•...", "DEBUG")
            time.sleep(delay)
    
    return None, 0, f"é‡è¯•{MAX_RETRIES}æ¬¡åå¤±è´¥"


def dedup_rules(rules):
    """é«˜æ€§èƒ½å»é‡é€»è¾‘"""
    
    # ç¬¬ä¸€å±‚ï¼šå®Œå…¨ç›¸åŒå»é‡
    seen_keys = {}
    unique_rules = []
    dup_removed = 0
    
    for rule in rules:
        p = parse_loon_rule(rule)
        if not p:
            continue
        key = (p[0], p[1].lower(), tuple(sorted([x.lower() for x in p[2] if x.lower() != 'no-resolve'])))
        if key not in seen_keys:
            seen_keys[key] = True
            unique_rules.append(rule)
        else:
            dup_removed += 1
    
    rules = unique_rules
    
    # åˆ†ç±»æ”¶é›†
    ip_raw, ip6_raw, dom_raw, suf_raw, key_raw = [], [], [], [], []
    
    for rule in rules:
        p = parse_loon_rule(rule)
        if not p:
            continue
        rtype, rval = p[0], p[1].lower()
        
        if rtype == 'IP-CIDR':
            ip_s, mask_s = rval.split('/')
            ip_int = ip_to_int(ip_s)
            if ip_int is not None:
                ip_raw.append((ip_int, int(mask_s), rule))
        elif rtype == 'IP-CIDR6':
            ip6_raw.append(rule)
        elif rtype == 'DOMAIN':
            dom_raw.append((rval, rule))
        elif rtype == 'DOMAIN-SUFFIX':
            suf_raw.append((rval, rule))
        elif rtype == 'DOMAIN-KEYWORD':
            key_raw.append(rule)
    
    # ç¬¬äºŒå±‚ï¼šIP-CIDRåŒ…å«å»é‡ï¼ˆå‡åºï¼Œå¤§ç½‘æ®µä¼˜å…ˆä¿ç•™ï¼‰
    ip_raw.sort(key=lambda x: x[1])
    kept_ip, ip_rem = [], 0
    
    for ip_i, m, r in ip_raw:
        is_covered = False
        for kept_ip_int, kept_mask, _ in kept_ip:
            shift = 32 - kept_mask
            if shift >= 0 and (ip_i >> shift) == (kept_ip_int >> shift):
                is_covered = True
                break
        if is_covered:
            ip_rem += 1
        else:
            kept_ip.append((ip_i, m, r))
    
    # ç¬¬ä¸‰å±‚ï¼šåç¼€å»é‡ï¼ˆçŸ­ä¼˜å…ˆï¼Œçˆ¶çº§å…ˆä¿ç•™ï¼‰
    suf_raw.sort(key=lambda x: len(x[0].split('.')))
    kept_suf_set, final_suf, suf_rem = set(), [], 0
    
    for d, r in suf_raw:
        parts = d.split('.')
        is_redundant = False
        for i in range(1, len(parts)):
            parent = '.'.join(parts[i:])
            if parent in kept_suf_set:
                is_redundant = True
                break
        
        if is_redundant:
            suf_rem += 1
        else:
            kept_suf_set.add(d)
            final_suf.append(r)
    
    # ç¬¬å››å±‚ï¼šåŸŸåè¢«åç¼€åŒ…å«
    final_dom, dom_rem = [], 0
    
    for d, r in dom_raw:
        parts = d.split('.')
        is_covered = False
        for i in range(len(parts) - 1):
            suffix = '.'.join(parts[i:])
            if suffix in kept_suf_set:
                is_covered = True
                break
        
        if is_covered:
            dom_rem += 1
        else:
            final_dom.append((d, r))
    
    # ç¬¬äº”å±‚ï¼šè·¨ç±»å‹å»é‡ï¼ˆçº¯IPåŸŸåè¢«CIDRè¦†ç›–ï¼‰
    final_dom_rules, cross_rem = [], 0
    
    for d, r in final_dom:
        ip_v = ip_to_int(d)
        if ip_v is None:
            final_dom_rules.append(r)
            continue
        
        is_covered = False
        for kept_ip_int, kept_mask, _ in kept_ip:
            shift = 32 - kept_mask
            if shift >= 0 and (ip_v >> shift) == (kept_ip_int >> shift):
                is_covered = True
                break
        
        if is_covered:
            cross_rem += 1
        else:
            final_dom_rules.append(r)
    
    # åˆå¹¶ç»“æœï¼šåŸŸå -> åç¼€ -> å…³é”®å­— -> IPv4 -> IPv6
    res = final_dom_rules + final_suf + key_raw + [x[2] for x in kept_ip] + ip6_raw
    total_rem = dup_removed + ip_rem + suf_rem + dom_rem + cross_rem
    
    return res, total_rem


def format_source_stats(source_stats):
    """æ ¼å¼åŒ–æºç»Ÿè®¡ä¿¡æ¯ï¼Œå¯¹é½è¾“å‡º"""
    if not source_stats:
        return []
    
    max_name_len = max(len(s['name']) for s in source_stats)
    name_width = max(max_name_len, 10)
    
    lines = []
    lines.append("# " + "=" * (name_width + 25))
    lines.append(f"# {'åç§°':<{name_width}} {'åŸå§‹':>8} {'æå–':>8} {'ä¸¢å¼ƒ':>8}")
    lines.append("# " + "-" * (name_width + 25))
    
    for s in source_stats:
        name = s['name']
        raw = s['raw']
        valid = s['valid']
        dropped = raw - valid
        lines.append(f"# {name:<{name_width}} {raw:>8} {valid:>8} {dropped:>8}")
    
    lines.append("# " + "=" * (name_width + 25))
    return lines


def main():
    """ä¸»å‡½æ•°"""
    log("å¯åŠ¨è§„åˆ™æŠ“å–...", "INFO")
    all_rules, source_stats = [], []
    
    total_start = time.time()
    
    for idx, src in enumerate(RULE_SOURCES, 1):
        log(f"[{idx}/{len(RULE_SOURCES)}] å¼€å§‹æ‹‰å–: {src['name']}")
        log(f"    URL: {src['url'][:60]}...", "DEBUG")
        
        content, lines_count, error = fetch_with_retry(src['url'], src['name'])
        
        if error:
            log(f"{src['name']} å¤±è´¥: {error}", "ERROR")
            source_stats.append({
                "name": src['name'],
                "raw": 0,
                "valid": 0,
                "error": error
            })
            continue
        
        proc_start = time.time()
        processed = [r for r in (process_line_smart(l) for l in content.splitlines()) if r]
        proc_time = time.time() - proc_start
        
        fmt_stats = {"DOMAIN": 0, "DOMAIN-SUFFIX": 0, "DOMAIN-KEYWORD": 0, "IP-CIDR": 0, "IP-CIDR6": 0, "other": 0}
        for r in processed:
            p = parse_loon_rule(r)
            if p and p[0] in fmt_stats:
                fmt_stats[p[0]] += 1
            else:
                fmt_stats["other"] += 1
        
        log(f"    æ ¼å¼è¯†åˆ«: D={fmt_stats['DOMAIN']}, D-S={fmt_stats['DOMAIN-SUFFIX']}, "
            f"D-K={fmt_stats['DOMAIN-KEYWORD']}, IP4={fmt_stats['IP-CIDR']}, IP6={fmt_stats['IP-CIDR6']}", "DEBUG")
        
        dedup_start = time.time()
        seen = set()
        unique_src = []
        for r in processed:
            if r not in seen:
                seen.add(r)
                unique_src.append(r)
        dedup_time = time.time() - dedup_start
        
        dropped = len(processed) - len(unique_src)
        log(f"    å¤„ç†å®Œæˆ: {len(unique_src)} æ¡ (è¯†åˆ«è€—æ—¶ {proc_time:.2f}s, å»é‡è€—æ—¶ {dedup_time:.2f}s, ä¸¢å¼ƒ {dropped} æ¡)", "DEBUG")
        
        all_rules.extend(unique_src)
        source_stats.append({
            "name": src['name'],
            "raw": lines_count,
            "valid": len(unique_src)
        })
        log(f"{src['name']} å®Œæˆ: {len(unique_src)} æ¡", "OK")
        
        if idx < len(RULE_SOURCES):
            time.sleep(0.5)
    
    total_elapsed = time.time() - total_start
    log(f"æ‰€æœ‰æºå¤„ç†å®Œæˆï¼Œæ€»è®¡ {len(all_rules)} æ¡ï¼Œè€—æ—¶ {total_elapsed:.2f}s", "INFO")
    
    log("å¼€å§‹å…¨å±€å»é‡...", "INFO")
    dedup_start = time.time()
    final, rem_count = dedup_rules(all_rules)
    dedup_time = time.time() - dedup_start
    log(f"å…¨å±€å»é‡å®Œæˆ: {len(final)} æ¡ (ç§»é™¤ {rem_count} æ¡ï¼Œè€—æ—¶ {dedup_time:.2f}s)", "INFO")
    
    prio = {'DOMAIN': 1, 'DOMAIN-SUFFIX': 2, 'DOMAIN-KEYWORD': 3, 'IP-CIDR': 4, 'IP-CIDR6': 5}
    final.sort(key=lambda r: (prio.get(parse_loon_rule(r)[0], 99), r.lower()))
    
    type_stats = {}
    for r in final:
        p = parse_loon_rule(r)
        if p:
            rtype = p[0]
            type_stats[rtype] = type_stats.get(rtype, 0) + 1
    
    header = [
        f"# Loon_ADåˆºå®¢",
        f"# ç”Ÿæˆæ—¶é—´: {get_beijing_time()}",
        f"# ç»Ÿè®¡: {len(final)} æ¡",
        f"# ä¼˜åŒ–: ç§»é™¤ {rem_count} æ¡å†—ä½™è§„åˆ™",
        f"# è®¢é˜…åœ°å€: {SUBSCRIBE_URL}",
    ]
    
    header.extend(format_source_stats(source_stats))
    
    header.append("# " + "-" * 40)
    for t in sorted(type_stats.keys(), key=lambda x: prio.get(x, 99)):
        header.append(f"# {t}: {type_stats[t]} æ¡")
    header.append("# " + "=" * 40)
    
    try:
        with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
            f.write('\n'.join(header) + '\n\n' + '\n'.join(final))
        log(f"æ–‡ä»¶å·²ä¿å­˜: {OUTPUT_FILE} ({len(final)} æ¡è§„åˆ™)", "OK")
    except Exception as e:
        log(f"æ–‡ä»¶ä¿å­˜å¤±è´¥: {e}", "ERROR")
        return
    
    log("ä»»åŠ¡å®Œæˆï¼", "OK")


if __name__ == "__main__":
    main()
