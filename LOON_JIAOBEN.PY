#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import requests  # ç”¨äºŽæ‹‰å–è¿œç¨‹è§„åˆ™æ–‡ä»¶
import re        # ç”¨äºŽéªŒè¯åŸŸååˆæ³•æ€§
from datetime import datetime, timedelta  # ç”¨äºŽç”ŸæˆåŒ—äº¬æ—¶é—´ç»Ÿè®¡

# â€”â€” æ ¸å¿ƒé…ç½®åŒº â€”â€”
# ä½ çš„ AGH åŽŸå§‹è§„åˆ™æºåœ°å€
AGH_SOURCE_URL = "https://ddcm1349.github.io/AGH/adguard_rules.txt"

# æŒ‰ç…§ä½ çš„è¦æ±‚è®¾å®šçš„é»‘ç™½åå•æ–‡ä»¶å
BLACKLIST_FILE = "Loon_é»‘åå•.txt"
WHITELIST_FILE = "Loon_ç™½åå•.txt"

def get_beijing_time():
    """èŽ·å–å¹¶æ ¼å¼åŒ–å½“å‰çš„åŒ—äº¬æ—¶é—´"""
    return (datetime.utcnow() + timedelta(hours=8)).strftime('%Y-%m-%d %H:%M:%S')

def extract_domain(line):
    """
    åˆ†æ‹£æå–é€»è¾‘ï¼š
    ä»Ž AGH è¯­æ³•ä¸­è¯†åˆ«å‡ºåŸŸåï¼Œå¹¶åŒºåˆ†é»‘ç™½åå•
    """
    line = line.strip()
    
    # 1. åŸºç¡€è¿‡æ»¤ï¼šè·³è¿‡ç©ºè¡Œã€æ³¨é‡Š(! #)ã€è§„åˆ™é›†æ ‡è®°([)ã€æ­£åˆ™(/)ä»¥åŠå¸¦$çš„å¤æ‚ä¿®é¥°ç¬¦
    if not line or line.startswith(('!', '#', '[')) or '/' in line or '$' in line:
        return None, None

    is_whitelist = False
    temp_line = line

    # 2. è¯†åˆ«ç™½åå•ï¼šè‹¥ä»¥ @@ å¼€å¤´åˆ™æ ‡è®°ä¸ºç™½åå•ï¼Œå¹¶å‰¥ç¦»ç¬¦å·
    if temp_line.startswith('@@'):
        is_whitelist = True
        temp_line = temp_line[2:]

    # 3. å¤„ç† AGH æ ‡å¿—æ€§çš„ || å‰ç¼€ï¼Œå¹¶æˆªæ–­ç»“å°¾çš„åˆ†éš”ç¬¦ ^
    if temp_line.startswith('||'):
        temp_line = temp_line[2:].split('^')[0]
    
    # 4. å…¼å®¹å¤„ç†ï¼šé’ˆå¯¹åŒ…å« DOMAIN, æˆ– DOMAIN-SUFFIX, çš„è¡Œ
    elif ',' in temp_line:
        parts = temp_line.split(',')
        for part in parts:
            p = part.strip()
            # åŒ…å«ç‚¹ä¸”ä¸æ˜¯å…¨å¤§å†™æŒ‡ä»¤ï¼ˆå¦‚ REJECTï¼‰åˆ™è®¤å®šä¸ºåŸŸå
            if '.' in p and not p.isupper():
                temp_line = p
                break
    
    # 5. çº¯å‡€åŒ–å¤„ç†ï¼šåŽ»æŽ‰å·¦ä¾§å‰å¯¼ç‚¹ã€è½¬å°å†™ã€ç§»é™¤ç«¯å£å·å’Œå¤šä½™ç¬¦å·
    domain = temp_line.lstrip('.').lower().split(':')[0].split('^')[0]

    # 6. åˆæ³•æ€§æ£€æŸ¥ï¼šç¡®ä¿æ˜¯åˆè§„çš„åŸŸåæ ¼å¼ï¼Œä¸”æŽ’é™¤çº¯ IP åœ°å€
    if '.' in domain and re.match(r'^[a-z0-9\-\.]+$', domain):
        if not domain.split('.')[-1].isdigit():
            return domain, is_whitelist
    
    return None, None

def save_to_file(filename, title, domains):
    """å°†æå–åˆ°çš„åˆ—è¡¨ä¿å­˜ä¸ºæ–‡ä»¶ï¼Œå¹¶å†™å…¥è¯¦ç»†çš„ç»Ÿè®¡æŠ¥è¡¨å¤´"""
    beijing_time = get_beijing_time()
    header = [
        f"# {title}",
        f"# ç”Ÿæˆæ—¶é—´: {beijing_time} (åŒ—äº¬æ—¶é—´)",
        f"# æå–æ€»æ•°: {len(domains)} æ¡",
        f"# æ¥æºåœ°å€: {AGH_SOURCE_URL}",
        "#" + "="*65 + "\n"
    ]
    with open(filename, 'w', encoding='utf-8') as f:
        f.write('\n'.join(header))  # å†™å…¥ç»Ÿè®¡å¤´
        f.write('\n'.join(sorted(domains)))  # å†™å…¥æŽ’åºåŽçš„çº¯åŸŸååˆ—è¡¨

def main():
    """ä¸»ç¨‹åºé€»è¾‘"""
    print(f"ðŸš€ æ­£åœ¨æ‹‰å–æºæ–‡ä»¶: {AGH_SOURCE_URL}")
    
    try:
        resp = requests.get(AGH_SOURCE_URL, timeout=30)
        resp.raise_for_status()
        lines = resp.text.splitlines()
    except Exception as e:
        print(f"âŒ æ‹‰å–å¤±è´¥: {e}")
        return

    black_list = []  # é»‘åå•ä¸´æ—¶å®¹å™¨
    white_list = []  # ç™½åå•ä¸´æ—¶å®¹å™¨

    # éåŽ†åŽŸå§‹è§„åˆ™è¿›è¡Œåˆ†æ‹£
    for line in lines:
        domain, is_white = extract_domain(line)
        if domain:
            if is_white:
                white_list.append(domain)
            else:
                black_list.append(domain)

    # ç¡®ä¿æœ€ç»ˆç»“æžœåŽ»é‡ï¼ˆé›†åˆåŽ»é‡ï¼‰
    black_list = list(dict.fromkeys(black_list))
    white_list = list(dict.fromkeys(white_list))

    # æ‰§è¡Œä¿å­˜æ“ä½œ
    save_to_file(BLACKLIST_FILE, "Loon åŸŸåé»‘åå• (BLACKLIST)", black_list)
    save_to_file(WHITELIST_FILE, "Loon åŸŸåç™½åå• (WHITELIST)", white_list)

    print(f"âœ… å¤„ç†å®Œæˆï¼")
    print(f"ðŸ“Š é»‘åå•: {len(black_list)} æ¡ -> {BLACKLIST_FILE}")
    print(f"ðŸ“Š ç™½åå•: {len(white_list)} æ¡ -> {WHITELIST_FILE}")

if __name__ == "__main__":
    main()
