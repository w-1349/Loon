#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import requests
import re
from datetime import datetime, timedelta

# è§„åˆ™æºé…ç½®åˆ—è¡¨ï¼ŒæŒ‰ä¼˜å…ˆçº§æ’åº
RULE_SOURCES = [
    {"name": "AdRules", "url": "https://raw.githubusercontent.com/Cats-Team/AdRules/main/adrules.list"},
    {"name": "anti-ad", "url": "https://anti-ad.net/surge2.txt"},
    {"name": "Advertising", "url": "https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/master/rule/Loon/Advertising/Advertising.list"},
    {"name": "Advertising_Domain", "url": "https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/master/rule/Loon/Advertising/Advertising_Domain.list"},
    {"name": "Privacy", "url": "https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/master/rule/Loon/Privacy/Privacy.list"},
    {"name": "Privacy_Domain", "url": "https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/master/rule/Loon/Privacy/Privacy_Domain.list"},
]

# è¾“å‡ºæ–‡ä»¶è·¯å¾„
OUTPUT_FILE = "Loon_rules.txt"
# è®¢é˜…åœ°å€
SUBSCRIBE_URL = "https://ddcm1349.github.io/Loon/Loon_rules.txt"


def get_beijing_time():
    """
    è·å–å½“å‰åŒ—äº¬æ—¶é—´
    Returns:
        str: æ ¼å¼åŒ–åçš„åŒ—äº¬æ—¶é—´å­—ç¬¦ä¸²ï¼Œæ ¼å¼ä¸º 'YYYY-MM-DD HH:MM:SS'
    """
    utc_now = datetime.utcnow()
    beijing_time = utc_now + timedelta(hours=8)
    return beijing_time.strftime('%Y-%m-%d %H:%M:%S')


def is_valid_domain(domain):
    """
    éªŒè¯å­—ç¬¦ä¸²æ˜¯å¦ä¸ºæœ‰æ•ˆçš„åŸŸåæ ¼å¼
    éªŒè¯è§„åˆ™ï¼š
    - é•¿åº¦ä¸è¶…è¿‡253ä¸ªå­—ç¬¦
    - åªèƒ½åŒ…å«å°å†™å­—æ¯ã€æ•°å­—ã€è¿å­—ç¬¦å’Œç‚¹å·
    - ä¸èƒ½ä»¥ç‚¹å·å¼€å¤´æˆ–ç»“å°¾ï¼Œä¸èƒ½åŒ…å«è¿ç»­ç‚¹å·
    - è‡³å°‘åŒ…å«ä¸¤ä¸ªæ ‡ç­¾ï¼ˆå¦‚ï¼šexample.comï¼‰
    - æ¯ä¸ªæ ‡ç­¾é•¿åº¦1-63å­—ç¬¦ï¼Œä¸èƒ½ä»¥è¿å­—ç¬¦å¼€å¤´æˆ–ç»“å°¾
    - é¡¶çº§åŸŸåä¸èƒ½å…¨æ˜¯æ•°å­—
    """
    if not domain or len(domain) > 253:
        return False
    if not re.match(r'^[a-z0-9\-\.]+$', domain):
        return False
    if '..' in domain or domain.startswith('.') or domain.endswith('.'):
        return False
    labels = domain.split('.')
    if len(labels) < 2:
        return False
    for label in labels:
        if not 1 <= len(label) <= 63:
            return False
        if label.startswith('-') or label.endswith('-'):
            return False
    if labels[-1].isdigit():
        return False
    return True


def is_valid_ip_cidr(ip_str):
    """éªŒè¯å­—ç¬¦ä¸²æ˜¯å¦ä¸ºæœ‰æ•ˆçš„IPv4 CIDRæ ¼å¼"""
    pattern = r'^(\d{1,3}\.){3}\d{1,3}/\d{1,2}$'
    if not re.match(pattern, ip_str):
        return False
    try:
        ip_part, mask_part = ip_str.split('/')
        mask = int(mask_part)
        if not (0 <= mask <= 32):
            return False
        parts = ip_part.split('.')
        for part in parts:
            num = int(part)
            if not 0 <= num <= 255:
                return False
        return True
    except:
        return False


def is_valid_pure_ip(ip_str):
    """éªŒè¯å­—ç¬¦ä¸²æ˜¯å¦ä¸ºæœ‰æ•ˆçš„çº¯IPv4åœ°å€"""
    if '/' in ip_str:
        return False
    if not re.match(r'^[\d\.]+$', ip_str):
        return False
    parts = ip_str.split('.')
    if len(parts) != 4:
        return False
    try:
        for part in parts:
            if not part:
                return False
            num = int(part)
            if not 0 <= num <= 255:
                return False
            if len(part) > 1 and part[0] == '0':
                return False
        return True
    except ValueError:
        return False


def is_loon_format(line):
    """æ£€æŸ¥è¡Œæ˜¯å¦ä¸ºLoonè§„åˆ™æ ¼å¼"""
    upper_line = line.upper()
    prefixes = ('DOMAIN,', 'DOMAIN-SUFFIX,', 'DOMAIN-KEYWORD,', 'IP-CIDR,', 'IP-CIDR6,')
    return any(upper_line.startswith(prefix) for prefix in prefixes)


def parse_loon_rule(line):
    """è§£æLoonè§„åˆ™è¡Œï¼Œæå–è§„åˆ™ç±»å‹ã€å€¼å’Œå‚æ•°"""
    parts = line.split(',')
    if len(parts) < 2:
        return None
    rule_type = parts[0].strip().upper()
    value = parts[1].strip()
    params = [p.strip() for p in parts[2:]] if len(parts) > 2 else []
    return (rule_type, value, params)


def normalize_rule(rule_type, value, params):
    """è§„èŒƒåŒ–è§„åˆ™æ ¼å¼ï¼Œç»Ÿä¸€å‚æ•°é¡ºåº"""
    other_params = [p for p in params if p.lower() != 'no-resolve']
    has_no_resolve = any(p.lower() == 'no-resolve' for p in params)
    final_params = other_params.copy()
    if has_no_resolve:
        final_params.append('no-resolve')
    if final_params:
        return f"{rule_type},{value},{','.join(final_params)}"
    return f"{rule_type},{value}"


def process_line_smart(line):
    """æ™ºèƒ½å¤„ç†è¡Œï¼Œæ”¯æŒå¤šç§è¾“å…¥æ ¼å¼è‡ªåŠ¨è¯†åˆ«å¹¶è½¬æ¢ä¸ºLoonæ ¼å¼"""
    line = line.strip()
    if not line or any(line.startswith(x) for x in ('#', '!', '[')):
        return None
    if is_loon_format(line):
        parsed = parse_loon_rule(line)
        if parsed:
            return normalize_rule(parsed[0], parsed[1], parsed[2])
    if is_valid_ip_cidr(line):
        return f"IP-CIDR,{line}"
    if is_valid_pure_ip(line):
        return f"DOMAIN,{line}"
    if line.startswith('.'):
        domain = line[1:].lower()
        if is_valid_domain(domain):
            return f"DOMAIN-SUFFIX,{domain}"
    domain = line.lower()
    if is_valid_domain(domain):
        return f"DOMAIN,{domain}"
    return None


def get_rule_priority(rule):
    """è·å–è§„åˆ™çš„æ’åºä¼˜å…ˆçº§"""
    parsed = parse_loon_rule(rule)
    if not parsed: return 99
    priority_map = {'DOMAIN': 1, 'DOMAIN-SUFFIX': 2, 'DOMAIN-KEYWORD': 3, 'IP-CIDR': 4, 'IP-CIDR6': 5}
    return priority_map.get(parsed[0], 99)


def dedup_rules(rules):
    """
    å¯¹è§„åˆ™åˆ—è¡¨è¿›è¡Œå¤šå±‚å»é‡å’Œä¼˜åŒ–
    ä½¿ç”¨å“ˆå¸ŒæŸ¥è¡¨æ³•ç¡®ä¿é«˜æ€§èƒ½å¤„ç†
    """
    # ç¬¬ä¸€å±‚ï¼šå®Œå…¨ç›¸åŒå»é‡
    unique_rules = []
    seen_keys = set()
    for rule in rules:
        p = parse_loon_rule(rule)
        if not p: continue
        key = (p[0], p[1].lower(), tuple(sorted([x.lower() for x in p[2]])))
        if key not in seen_keys:
            seen_keys.add(key)
            unique_rules.append(rule)
    
    # åˆ†ç±»æ”¶é›†
    ip_cidr_list = []
    domain_list = []
    suffix_list = []
    other_list = []

    for rule in unique_rules:
        p = parse_loon_rule(rule)
        rtype, rval = p[0], p[1].lower()
        if rtype == 'IP-CIDR':
            parts = rval.split('/')
            ip_int = sum(int(b) << (24 - 8 * i) for i, b in enumerate(parts[0].split('.')))
            ip_cidr_list.append({'int': ip_int, 'mask': int(parts[1]), 'raw': rule})
        elif rtype == 'DOMAIN': domain_list.append((rval, rule))
        elif rtype == 'DOMAIN-SUFFIX': suffix_list.append((rval, rule))
        else: other_list.append(rule)

    # ç¬¬äºŒå±‚ï¼šIP-CIDR å»é‡ (å‡åºï¼šå¤§èŒƒå›´åœ¨å‰)
    ip_cidr_list.sort(key=lambda x: x['mask'])
    kept_ip = []
    removed_count = 0
    for item in ip_cidr_list:
        is_covered = any(item['int'] >> (32 - k['mask']) == k['int'] >> (32 - k['mask']) for k in kept_ip)
        if is_covered: removed_count += 1
        else: kept_ip.append(item)

    # ç¬¬ä¸‰å±‚ï¼šåç¼€åŠåŸŸåå»é‡ (å“ˆå¸Œè·¯å¾„åŒ¹é…ä¼˜åŒ–)
    # è¿‡æ»¤å•æ ‡ç­¾åç¼€ (ä¾‹å¦‚ .com)ï¼Œåªå¤„ç†å¤šæ ‡ç­¾åç¼€
    valid_suffixes = [s for s in suffix_list if len(s[0].split('.')) >= 2]
    valid_suffixes.sort(key=lambda x: len(x[0].split('.')))
    
    kept_suffix_set = set()
    final_suffix_rules = []
    for d, r in valid_suffixes:
        parts = d.split('.')
        # æ£€æŸ¥çˆ¶åŸŸæ˜¯å¦å·²åœ¨åç¼€è§„åˆ™ä¸­
        if any('.'.join(parts[i:]) in kept_suffix_set for i in range(1, len(parts) - 1)):
            removed_count += 1
        else:
            kept_suffix_set.add(d)
            final_suffix_rules.append(r)

    # ç²¾ç¡®åŸŸåè¢«åç¼€è¦†ç›–å»é‡
    final_domain_rules = []
    for d, r in domain_list:
        parts = d.split('.')
        if any('.'.join(parts[i:]) in kept_suffix_set for i in range(len(parts) - 1)):
            removed_count += 1
        else:
            # è·¨ç±»å‹å»é‡ï¼šè¢«IPèŒƒå›´è¦†ç›–çš„çº¯IPåŸŸå
            ip_val = sum(int(b) << (24 - 8 * i) for i, b in enumerate(d.split('.'))) if re.match(r'^[\d\.]+$', d) and d.count('.') == 3 else None
            is_ip_covered = False
            if ip_val:
                is_ip_covered = any(ip_val >> (32 - k['mask']) == k['int'] >> (32 - k['mask']) for k in kept_ip)
            
            if is_ip_covered: removed_count += 1
            else: final_domain_rules.append(r)

    # åˆå¹¶ç»“æœ
    final_rules = final_domain_rules + final_suffix_rules + other_list + [x['raw'] for x in kept_ip]
    return final_rules, removed_count


def main():
    """ä¸»å‡½æ•°ï¼šæ‰§è¡Œè§„åˆ™æ‹‰å–ã€ä¼˜åŒ–åŠå†™å…¥"""
    print(f"[{get_beijing_time()}] ğŸš€ å¯åŠ¨è§„åˆ™æŠ“å–...")
    all_rules = []
    source_stats = []
    headers = {'User-Agent': 'Mozilla/5.0 (compatible; RuleFetcher/1.0)'}

    for src in RULE_SOURCES:
        try:
            print(f"ğŸ“¥ æ‹‰å–: {src['name']}...", flush=True)
            resp = requests.get(src['url'], timeout=30, headers=headers)
            resp.raise_for_status()
            lines = resp.text.splitlines()
            processed = [r for r in (process_line_smart(l) for l in lines) if r]
            
            # æºå†…å»é‡å¹¶ç»Ÿè®¡
            unique_p = []
            seen = set()
            for r in processed:
                p = parse_loon_rule(r)
                k = (p[0], p[1].lower())
                if k not in seen:
                    seen.add(k); unique_p.append(r)
            
            all_rules.extend(unique_p)
            source_stats.append({"name": src['name'], "raw": len(lines), "valid": len(unique_p)})
            print(f"âœ… å®Œæˆ ({len(unique_p)} æ¡)", flush=True)
        except Exception as e:
            print(f"âŒ å¤±è´¥: {e}", flush=True)

    print(f"ğŸ”„ æ‰§è¡Œå…¨å±€å»é‡ä¸é«˜æ€§èƒ½ä¼˜åŒ–...", flush=True)
    final_rules, total_removed = dedup_rules(all_rules)
    final_rules.sort(key=lambda r: (get_rule_priority(r), r.lower()))

    # æ„å»ºæ–‡ä»¶å¤´éƒ¨ä¿¡æ¯
    header = [
        f"# Loon_ADåˆºå®¢",
        f"# ç”Ÿæˆæ—¶é—´: {get_beijing_time()}",
        f"# ç»Ÿè®¡: {len(final_rules)} æ¡",
        f"# ä¼˜åŒ–: ç§»é™¤ {total_removed} æ¡å†—ä½™è§„åˆ™",
        f"# è®¢é˜…åœ°å€: {SUBSCRIBE_URL}",
        "# " + "=" * 58
    ]
    for s in source_stats:
        header.append(f"# æº: {s['name']} | åŸå§‹ {s['raw']} | æœ‰æ•ˆ {s['valid']}")
    
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        f.write('\n'.join(header) + '\n\n' + '\n'.join(final_rules))
    
    print(f"[{get_beijing_time()}] ğŸ‰ ä»»åŠ¡å®Œæˆï¼Œå·²ä¿å­˜è‡³ {OUTPUT_FILE}")


if __name__ == "__main__":
    main()
